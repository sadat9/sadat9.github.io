{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVM+kzaIAvgnivBGQ+ksQK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2b53e328","executionInfo":{"status":"ok","timestamp":1751652077839,"user_tz":-360,"elapsed":4111,"user":{"displayName":"sadat rahman","userId":"00315844507455805433"}},"outputId":"f3bf89d5-947a-444c-a5cc-fe87a7cfb14c"},"source":["%pip install opencv-python ultralytics mediapipe"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.162)\n","Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n","Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n","Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.8)\n","Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n","Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a172db19","executionInfo":{"status":"ok","timestamp":1751652102217,"user_tz":-360,"elapsed":81,"user":{"displayName":"sadat rahman","userId":"00315844507455805433"}},"outputId":"ff99cecf-02d5-4cb5-ddc1-97a78fcef037"},"source":["import cv2\n","\n","video_path = 'desk_video.mp4'\n","video_capture = cv2.VideoCapture(video_path)\n","\n","if not video_capture.isOpened():\n","    print(f\"Error: Could not load video from {video_path}\")\n","else:\n","    print(f\"Video loaded successfully from {video_path}\")"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Video loaded successfully from desk_video.mp4\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2e3f36ba","executionInfo":{"status":"ok","timestamp":1751652111040,"user_tz":-360,"elapsed":3860,"user":{"displayName":"sadat rahman","userId":"00315844507455805433"}},"outputId":"cd6f8df8-f436-4e75-a39c-356e41f3a8ae"},"source":["while video_capture.isOpened():\n","    ret, frame = video_capture.read()\n","    if not ret:\n","        break\n","    # Process the frame\n","    pass\n","\n","video_capture.release()\n","print(\"Finished iterating through video frames.\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Finished iterating through video frames.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bf767b1f","executionInfo":{"status":"ok","timestamp":1751652277296,"user_tz":-360,"elapsed":159039,"user":{"displayName":"sadat rahman","userId":"00315844507455805433"}},"outputId":"303205af-5f00-4341-faf6-53a1df7b64f6"},"source":["from ultralytics import YOLO\n","\n","# Load a pre-trained YOLO model\n","# Using 'yolov8n.pt' which is a small model but should detect people and potentially hands\n","model = YOLO('yolov8n.pt')\n","\n","frame_detection_results = []\n","\n","video_capture = cv2.VideoCapture(video_path)\n","\n","while video_capture.isOpened():\n","    ret, frame = video_capture.read()\n","    if not ret:\n","        break\n","\n","    # Perform object detection on the frame\n","    results = model(frame)\n","\n","    # Store the results\n","    frame_detection_results.append(results)\n","\n","video_capture.release()\n","\n","print(\"Finished object detection on video frames.\")"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6.25M/6.25M [00:00<00:00, 59.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 8 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 316.1ms\n","Speed: 24.4ms preprocess, 316.1ms inference, 43.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 124.9ms\n","Speed: 4.9ms preprocess, 124.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 7 laptops, 1 keyboard, 119.5ms\n","Speed: 6.2ms preprocess, 119.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 8 laptops, 1 keyboard, 114.3ms\n","Speed: 6.0ms preprocess, 114.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 110.5ms\n","Speed: 4.8ms preprocess, 110.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 7 laptops, 1 keyboard, 119.5ms\n","Speed: 2.9ms preprocess, 119.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 2 chairs, 1 couch, 5 tvs, 7 laptops, 1 keyboard, 101.4ms\n","Speed: 4.2ms preprocess, 101.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 100.5ms\n","Speed: 4.7ms preprocess, 100.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 cups, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 102.3ms\n","Speed: 3.7ms preprocess, 102.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 cups, 2 chairs, 1 couch, 4 tvs, 7 laptops, 1 keyboard, 109.3ms\n","Speed: 4.9ms preprocess, 109.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 cups, 2 chairs, 1 couch, 4 tvs, 7 laptops, 1 keyboard, 125.5ms\n","Speed: 4.3ms preprocess, 125.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 2 cups, 1 chair, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 103.3ms\n","Speed: 5.0ms preprocess, 103.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 bottle, 2 cups, 1 chair, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 103.6ms\n","Speed: 3.7ms preprocess, 103.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 bottle, 2 cups, 1 chair, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 142.9ms\n","Speed: 3.0ms preprocess, 142.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 3 tvs, 8 laptops, 1 keyboard, 191.3ms\n","Speed: 5.6ms preprocess, 191.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 161.1ms\n","Speed: 9.0ms preprocess, 161.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 150.1ms\n","Speed: 10.5ms preprocess, 150.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 10 laptops, 1 keyboard, 149.1ms\n","Speed: 5.9ms preprocess, 149.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 160.4ms\n","Speed: 5.4ms preprocess, 160.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 188.7ms\n","Speed: 4.7ms preprocess, 188.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 140.6ms\n","Speed: 5.0ms preprocess, 140.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 168.1ms\n","Speed: 3.8ms preprocess, 168.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 108.2ms\n","Speed: 4.5ms preprocess, 108.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 8 tvs, 7 laptops, 1 keyboard, 103.1ms\n","Speed: 5.1ms preprocess, 103.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 8 tvs, 7 laptops, 1 keyboard, 102.8ms\n","Speed: 4.2ms preprocess, 102.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 7 laptops, 1 keyboard, 106.7ms\n","Speed: 3.9ms preprocess, 106.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 119.6ms\n","Speed: 4.1ms preprocess, 119.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 109.6ms\n","Speed: 5.9ms preprocess, 109.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 8 tvs, 7 laptops, 1 keyboard, 115.2ms\n","Speed: 4.1ms preprocess, 115.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 117.4ms\n","Speed: 4.3ms preprocess, 117.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 7 laptops, 1 keyboard, 129.8ms\n","Speed: 4.7ms preprocess, 129.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 7 laptops, 1 keyboard, 114.6ms\n","Speed: 5.8ms preprocess, 114.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 7 laptops, 1 keyboard, 112.1ms\n","Speed: 4.1ms preprocess, 112.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 113.3ms\n","Speed: 4.0ms preprocess, 113.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 120.8ms\n","Speed: 2.6ms preprocess, 120.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 100.1ms\n","Speed: 4.3ms preprocess, 100.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 8 tvs, 8 laptops, 1 keyboard, 118.8ms\n","Speed: 5.7ms preprocess, 118.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 110.6ms\n","Speed: 3.4ms preprocess, 110.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 106.9ms\n","Speed: 4.9ms preprocess, 106.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 99.4ms\n","Speed: 4.6ms preprocess, 99.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 8 tvs, 7 laptops, 1 keyboard, 103.1ms\n","Speed: 3.6ms preprocess, 103.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 8 tvs, 8 laptops, 1 keyboard, 110.7ms\n","Speed: 2.7ms preprocess, 110.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 124.2ms\n","Speed: 6.4ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 114.0ms\n","Speed: 4.6ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 122.0ms\n","Speed: 5.4ms preprocess, 122.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 122.6ms\n","Speed: 4.2ms preprocess, 122.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 114.1ms\n","Speed: 5.3ms preprocess, 114.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 112.8ms\n","Speed: 5.4ms preprocess, 112.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 105.0ms\n","Speed: 6.9ms preprocess, 105.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 120.3ms\n","Speed: 4.8ms preprocess, 120.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 121.8ms\n","Speed: 5.7ms preprocess, 121.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 107.5ms\n","Speed: 4.9ms preprocess, 107.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 7 laptops, 1 keyboard, 106.1ms\n","Speed: 7.9ms preprocess, 106.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 131.2ms\n","Speed: 3.9ms preprocess, 131.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 113.9ms\n","Speed: 5.2ms preprocess, 113.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 118.1ms\n","Speed: 5.2ms preprocess, 118.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 116.9ms\n","Speed: 4.8ms preprocess, 116.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 122.3ms\n","Speed: 4.2ms preprocess, 122.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 102.4ms\n","Speed: 3.9ms preprocess, 102.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 12 laptops, 1 keyboard, 110.4ms\n","Speed: 3.6ms preprocess, 110.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 117.2ms\n","Speed: 4.5ms preprocess, 117.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 102.9ms\n","Speed: 3.7ms preprocess, 102.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 103.2ms\n","Speed: 4.3ms preprocess, 103.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 9 laptops, 1 keyboard, 99.9ms\n","Speed: 3.6ms preprocess, 99.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 97.5ms\n","Speed: 4.4ms preprocess, 97.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 106.0ms\n","Speed: 3.8ms preprocess, 106.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 11 laptops, 1 keyboard, 110.2ms\n","Speed: 3.1ms preprocess, 110.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 11 laptops, 1 keyboard, 110.3ms\n","Speed: 3.9ms preprocess, 110.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 95.2ms\n","Speed: 5.2ms preprocess, 95.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 118.3ms\n","Speed: 2.7ms preprocess, 118.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 100.4ms\n","Speed: 5.0ms preprocess, 100.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 106.9ms\n","Speed: 3.6ms preprocess, 106.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 102.4ms\n","Speed: 4.6ms preprocess, 102.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 107.4ms\n","Speed: 3.5ms preprocess, 107.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 119.3ms\n","Speed: 4.3ms preprocess, 119.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 116.5ms\n","Speed: 3.8ms preprocess, 116.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 112.6ms\n","Speed: 4.7ms preprocess, 112.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 135.6ms\n","Speed: 6.4ms preprocess, 135.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 106.6ms\n","Speed: 4.8ms preprocess, 106.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 114.1ms\n","Speed: 5.6ms preprocess, 114.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 132.6ms\n","Speed: 4.4ms preprocess, 132.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 105.7ms\n","Speed: 3.9ms preprocess, 105.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 113.4ms\n","Speed: 3.8ms preprocess, 113.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 116.7ms\n","Speed: 4.9ms preprocess, 116.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 111.4ms\n","Speed: 3.9ms preprocess, 111.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 102.6ms\n","Speed: 3.9ms preprocess, 102.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 99.9ms\n","Speed: 4.4ms preprocess, 99.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 104.2ms\n","Speed: 3.6ms preprocess, 104.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 97.3ms\n","Speed: 4.3ms preprocess, 97.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 1 couch, 5 tvs, 12 laptops, 1 keyboard, 104.4ms\n","Speed: 2.9ms preprocess, 104.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 6 tvs, 13 laptops, 1 keyboard, 124.9ms\n","Speed: 4.4ms preprocess, 124.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 112.4ms\n","Speed: 5.9ms preprocess, 112.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 109.1ms\n","Speed: 5.0ms preprocess, 109.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 104.9ms\n","Speed: 4.0ms preprocess, 104.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 106.2ms\n","Speed: 4.3ms preprocess, 106.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 110.3ms\n","Speed: 4.1ms preprocess, 110.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 5 tvs, 12 laptops, 1 keyboard, 110.8ms\n","Speed: 5.0ms preprocess, 110.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 121.5ms\n","Speed: 4.1ms preprocess, 121.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 114.7ms\n","Speed: 10.7ms preprocess, 114.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 3 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 135.0ms\n","Speed: 4.7ms preprocess, 135.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 145.1ms\n","Speed: 8.5ms preprocess, 145.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 157.9ms\n","Speed: 2.9ms preprocess, 157.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 136.9ms\n","Speed: 5.4ms preprocess, 136.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 158.8ms\n","Speed: 4.0ms preprocess, 158.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 142.2ms\n","Speed: 4.3ms preprocess, 142.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 161.9ms\n","Speed: 3.3ms preprocess, 161.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 151.9ms\n","Speed: 3.9ms preprocess, 151.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 135.4ms\n","Speed: 5.9ms preprocess, 135.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 99.5ms\n","Speed: 3.0ms preprocess, 99.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 104.5ms\n","Speed: 3.5ms preprocess, 104.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 101.6ms\n","Speed: 3.8ms preprocess, 101.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 3 tvs, 8 laptops, 1 keyboard, 106.6ms\n","Speed: 3.4ms preprocess, 106.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 3 chairs, 1 couch, 2 tvs, 9 laptops, 1 keyboard, 120.2ms\n","Speed: 4.2ms preprocess, 120.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 109.6ms\n","Speed: 4.6ms preprocess, 109.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 chairs, 1 couch, 3 tvs, 9 laptops, 1 keyboard, 103.8ms\n","Speed: 5.3ms preprocess, 103.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 2 tvs, 8 laptops, 1 keyboard, 102.9ms\n","Speed: 4.3ms preprocess, 102.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 2 tvs, 8 laptops, 1 keyboard, 104.2ms\n","Speed: 3.4ms preprocess, 104.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 3 tvs, 8 laptops, 1 keyboard, 104.3ms\n","Speed: 3.8ms preprocess, 104.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 3 tvs, 8 laptops, 1 keyboard, 99.9ms\n","Speed: 4.1ms preprocess, 99.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 8 laptops, 1 keyboard, 103.9ms\n","Speed: 2.3ms preprocess, 103.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 108.5ms\n","Speed: 5.6ms preprocess, 108.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 100.9ms\n","Speed: 2.8ms preprocess, 100.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 chair, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 113.0ms\n","Speed: 5.4ms preprocess, 113.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 3 tvs, 10 laptops, 1 keyboard, 101.4ms\n","Speed: 3.9ms preprocess, 101.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 chair, 1 couch, 3 tvs, 9 laptops, 1 keyboard, 105.3ms\n","Speed: 4.5ms preprocess, 105.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 chair, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 99.6ms\n","Speed: 4.3ms preprocess, 99.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 chair, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 123.0ms\n","Speed: 3.6ms preprocess, 123.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 2 tvs, 10 laptops, 1 keyboard, 105.9ms\n","Speed: 4.2ms preprocess, 105.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 3 tvs, 9 laptops, 1 keyboard, 114.0ms\n","Speed: 3.0ms preprocess, 114.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 chair, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 115.6ms\n","Speed: 3.2ms preprocess, 115.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 101.8ms\n","Speed: 4.0ms preprocess, 101.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 103.6ms\n","Speed: 4.1ms preprocess, 103.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 3 tvs, 11 laptops, 1 keyboard, 101.3ms\n","Speed: 5.4ms preprocess, 101.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 3 tvs, 11 laptops, 1 keyboard, 109.6ms\n","Speed: 4.4ms preprocess, 109.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 102.9ms\n","Speed: 3.4ms preprocess, 102.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 97.2ms\n","Speed: 4.0ms preprocess, 97.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 4 tvs, 8 laptops, 1 keyboard, 114.7ms\n","Speed: 2.8ms preprocess, 114.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 3 tvs, 8 laptops, 1 keyboard, 117.3ms\n","Speed: 5.6ms preprocess, 117.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 3 tvs, 8 laptops, 1 keyboard, 119.3ms\n","Speed: 3.8ms preprocess, 119.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 4 tvs, 7 laptops, 1 keyboard, 103.8ms\n","Speed: 4.9ms preprocess, 103.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 102.3ms\n","Speed: 4.6ms preprocess, 102.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 chair, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 105.7ms\n","Speed: 4.8ms preprocess, 105.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 108.1ms\n","Speed: 3.6ms preprocess, 108.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 124.6ms\n","Speed: 4.0ms preprocess, 124.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 121.8ms\n","Speed: 6.7ms preprocess, 121.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 141.7ms\n","Speed: 5.4ms preprocess, 141.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 121.5ms\n","Speed: 3.7ms preprocess, 121.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 113.1ms\n","Speed: 6.1ms preprocess, 113.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 118.2ms\n","Speed: 4.4ms preprocess, 118.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 121.1ms\n","Speed: 5.2ms preprocess, 121.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 116.0ms\n","Speed: 4.1ms preprocess, 116.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 103.0ms\n","Speed: 6.3ms preprocess, 103.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 117.3ms\n","Speed: 5.6ms preprocess, 117.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 98.2ms\n","Speed: 4.1ms preprocess, 98.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 111.5ms\n","Speed: 3.3ms preprocess, 111.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 104.1ms\n","Speed: 4.4ms preprocess, 104.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 111.1ms\n","Speed: 7.0ms preprocess, 111.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 115.3ms\n","Speed: 5.0ms preprocess, 115.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 100.5ms\n","Speed: 3.1ms preprocess, 100.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 122.1ms\n","Speed: 4.4ms preprocess, 122.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 112.4ms\n","Speed: 4.9ms preprocess, 112.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 115.4ms\n","Speed: 5.9ms preprocess, 115.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 111.0ms\n","Speed: 3.9ms preprocess, 111.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 113.9ms\n","Speed: 4.8ms preprocess, 113.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 126.2ms\n","Speed: 5.1ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 110.2ms\n","Speed: 6.4ms preprocess, 110.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 116.2ms\n","Speed: 4.2ms preprocess, 116.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 1 couch, 7 tvs, 7 laptops, 1 keyboard, 105.9ms\n","Speed: 4.1ms preprocess, 105.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 7 tvs, 5 laptops, 1 keyboard, 116.5ms\n","Speed: 4.5ms preprocess, 116.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 1 couch, 6 tvs, 5 laptops, 1 keyboard, 99.7ms\n","Speed: 3.8ms preprocess, 99.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 1 couch, 6 tvs, 5 laptops, 1 keyboard, 103.2ms\n","Speed: 3.3ms preprocess, 103.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 1 couch, 6 tvs, 6 laptops, 1 keyboard, 99.0ms\n","Speed: 4.3ms preprocess, 99.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 96.7ms\n","Speed: 4.0ms preprocess, 96.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 1 couch, 6 tvs, 6 laptops, 1 keyboard, 96.7ms\n","Speed: 4.1ms preprocess, 96.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 108.7ms\n","Speed: 2.9ms preprocess, 108.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 118.7ms\n","Speed: 4.3ms preprocess, 118.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 106.8ms\n","Speed: 3.8ms preprocess, 106.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 110.9ms\n","Speed: 4.2ms preprocess, 110.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 104.0ms\n","Speed: 3.2ms preprocess, 104.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 103.4ms\n","Speed: 3.8ms preprocess, 103.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 101.0ms\n","Speed: 3.8ms preprocess, 101.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 7 tvs, 9 laptops, 1 keyboard, 99.6ms\n","Speed: 3.5ms preprocess, 99.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 99.5ms\n","Speed: 3.1ms preprocess, 99.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 104.2ms\n","Speed: 14.0ms preprocess, 104.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 109.1ms\n","Speed: 4.6ms preprocess, 109.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 108.2ms\n","Speed: 3.7ms preprocess, 108.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 105.1ms\n","Speed: 3.1ms preprocess, 105.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 129.6ms\n","Speed: 3.8ms preprocess, 129.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 139.5ms\n","Speed: 4.7ms preprocess, 139.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 148.1ms\n","Speed: 4.1ms preprocess, 148.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 126.1ms\n","Speed: 3.2ms preprocess, 126.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 128.4ms\n","Speed: 6.5ms preprocess, 128.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 125.0ms\n","Speed: 4.5ms preprocess, 125.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 1 couch, 7 tvs, 9 laptops, 1 keyboard, 140.1ms\n","Speed: 5.1ms preprocess, 140.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 139.9ms\n","Speed: 3.2ms preprocess, 139.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 136.4ms\n","Speed: 4.3ms preprocess, 136.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 134.6ms\n","Speed: 3.5ms preprocess, 134.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 125.1ms\n","Speed: 4.4ms preprocess, 125.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 cups, 3 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 113.5ms\n","Speed: 4.5ms preprocess, 113.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 135.1ms\n","Speed: 5.2ms preprocess, 135.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 116.2ms\n","Speed: 6.2ms preprocess, 116.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 110.4ms\n","Speed: 5.0ms preprocess, 110.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 111.5ms\n","Speed: 3.9ms preprocess, 111.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 119.3ms\n","Speed: 4.6ms preprocess, 119.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 105.6ms\n","Speed: 5.1ms preprocess, 105.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 293.5ms\n","Speed: 4.8ms preprocess, 293.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 124.3ms\n","Speed: 3.4ms preprocess, 124.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 122.6ms\n","Speed: 5.3ms preprocess, 122.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 117.5ms\n","Speed: 5.3ms preprocess, 117.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 130.9ms\n","Speed: 4.9ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 267.2ms\n","Speed: 4.0ms preprocess, 267.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 102.9ms\n","Speed: 3.8ms preprocess, 102.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 110.7ms\n","Speed: 3.9ms preprocess, 110.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 102.6ms\n","Speed: 4.2ms preprocess, 102.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 105.2ms\n","Speed: 3.1ms preprocess, 105.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 166.7ms\n","Speed: 15.6ms preprocess, 166.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 135.9ms\n","Speed: 3.9ms preprocess, 135.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 4 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 108.7ms\n","Speed: 5.5ms preprocess, 108.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 106.3ms\n","Speed: 4.1ms preprocess, 106.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 102.4ms\n","Speed: 3.8ms preprocess, 102.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 115.8ms\n","Speed: 4.2ms preprocess, 115.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 98.6ms\n","Speed: 3.9ms preprocess, 98.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 108.9ms\n","Speed: 3.4ms preprocess, 108.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 104.3ms\n","Speed: 4.4ms preprocess, 104.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 105.3ms\n","Speed: 5.1ms preprocess, 105.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 113.9ms\n","Speed: 5.2ms preprocess, 113.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 4 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 115.5ms\n","Speed: 3.7ms preprocess, 115.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 4 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 112.8ms\n","Speed: 3.8ms preprocess, 112.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 4 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 128.5ms\n","Speed: 4.4ms preprocess, 128.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 134.2ms\n","Speed: 4.9ms preprocess, 134.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 120.4ms\n","Speed: 6.1ms preprocess, 120.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 131.3ms\n","Speed: 4.8ms preprocess, 131.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 115.8ms\n","Speed: 5.2ms preprocess, 115.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 15 laptops, 1 keyboard, 104.8ms\n","Speed: 4.2ms preprocess, 104.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 3 tvs, 13 laptops, 1 keyboard, 107.8ms\n","Speed: 3.1ms preprocess, 107.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 108.6ms\n","Speed: 4.4ms preprocess, 108.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 98.7ms\n","Speed: 3.5ms preprocess, 98.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 100.9ms\n","Speed: 4.9ms preprocess, 100.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 3 tvs, 13 laptops, 1 keyboard, 107.5ms\n","Speed: 3.4ms preprocess, 107.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 97.5ms\n","Speed: 3.6ms preprocess, 97.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 107.6ms\n","Speed: 3.7ms preprocess, 107.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 120.2ms\n","Speed: 4.3ms preprocess, 120.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 118.4ms\n","Speed: 3.0ms preprocess, 118.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 123.6ms\n","Speed: 5.9ms preprocess, 123.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 132.6ms\n","Speed: 5.9ms preprocess, 132.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 111.4ms\n","Speed: 5.4ms preprocess, 111.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 126.4ms\n","Speed: 3.7ms preprocess, 126.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 128.9ms\n","Speed: 4.8ms preprocess, 128.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 12 laptops, 1 keyboard, 107.9ms\n","Speed: 5.0ms preprocess, 107.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 99.3ms\n","Speed: 3.8ms preprocess, 99.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 11 laptops, 1 keyboard, 110.0ms\n","Speed: 4.0ms preprocess, 110.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 13 laptops, 1 keyboard, 112.5ms\n","Speed: 4.0ms preprocess, 112.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 105.6ms\n","Speed: 3.9ms preprocess, 105.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 12 laptops, 1 keyboard, 113.8ms\n","Speed: 4.5ms preprocess, 113.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 14 laptops, 1 keyboard, 102.4ms\n","Speed: 4.3ms preprocess, 102.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 14 laptops, 1 keyboard, 107.1ms\n","Speed: 4.3ms preprocess, 107.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 14 laptops, 1 keyboard, 106.1ms\n","Speed: 3.0ms preprocess, 106.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 14 laptops, 1 keyboard, 113.2ms\n","Speed: 6.0ms preprocess, 113.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 13 laptops, 1 keyboard, 119.0ms\n","Speed: 3.6ms preprocess, 119.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 12 laptops, 1 keyboard, 150.5ms\n","Speed: 4.8ms preprocess, 150.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 13 laptops, 1 keyboard, 112.6ms\n","Speed: 6.2ms preprocess, 112.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 13 laptops, 1 keyboard, 133.4ms\n","Speed: 4.6ms preprocess, 133.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 14 laptops, 1 keyboard, 124.9ms\n","Speed: 4.1ms preprocess, 124.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 14 laptops, 1 keyboard, 116.4ms\n","Speed: 5.7ms preprocess, 116.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 14 laptops, 1 keyboard, 107.3ms\n","Speed: 4.3ms preprocess, 107.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 11 laptops, 1 keyboard, 103.1ms\n","Speed: 4.9ms preprocess, 103.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 14 laptops, 1 keyboard, 113.4ms\n","Speed: 3.9ms preprocess, 113.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 13 laptops, 1 keyboard, 102.5ms\n","Speed: 3.6ms preprocess, 102.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 11 laptops, 1 keyboard, 118.3ms\n","Speed: 4.4ms preprocess, 118.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 12 laptops, 1 keyboard, 181.3ms\n","Speed: 5.5ms preprocess, 181.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 3 tvs, 12 laptops, 1 keyboard, 166.5ms\n","Speed: 5.6ms preprocess, 166.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 128.2ms\n","Speed: 4.4ms preprocess, 128.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 129.6ms\n","Speed: 4.5ms preprocess, 129.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 154.5ms\n","Speed: 4.8ms preprocess, 154.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 3 tvs, 13 laptops, 1 keyboard, 158.2ms\n","Speed: 3.9ms preprocess, 158.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 152.9ms\n","Speed: 4.3ms preprocess, 152.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 137.1ms\n","Speed: 6.9ms preprocess, 137.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 3 tvs, 10 laptops, 1 keyboard, 108.2ms\n","Speed: 3.9ms preprocess, 108.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 3 tvs, 11 laptops, 1 keyboard, 102.8ms\n","Speed: 4.0ms preprocess, 102.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 101.5ms\n","Speed: 3.7ms preprocess, 101.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 129.2ms\n","Speed: 3.5ms preprocess, 129.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 3 tvs, 14 laptops, 1 keyboard, 109.0ms\n","Speed: 4.2ms preprocess, 109.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 4 tvs, 15 laptops, 1 keyboard, 110.4ms\n","Speed: 3.3ms preprocess, 110.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 13 laptops, 1 keyboard, 108.4ms\n","Speed: 5.7ms preprocess, 108.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 115.1ms\n","Speed: 4.4ms preprocess, 115.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 107.9ms\n","Speed: 4.1ms preprocess, 107.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 113.7ms\n","Speed: 3.4ms preprocess, 113.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 131.2ms\n","Speed: 5.1ms preprocess, 131.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 134.2ms\n","Speed: 6.6ms preprocess, 134.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 126.9ms\n","Speed: 4.9ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 115.7ms\n","Speed: 4.0ms preprocess, 115.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 3 tvs, 8 laptops, 1 keyboard, 116.0ms\n","Speed: 5.3ms preprocess, 116.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 115.6ms\n","Speed: 4.9ms preprocess, 115.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 105.2ms\n","Speed: 4.9ms preprocess, 105.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 3 tvs, 9 laptops, 1 keyboard, 99.6ms\n","Speed: 3.2ms preprocess, 99.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 bottle, 1 cup, 3 chairs, 1 couch, 3 tvs, 10 laptops, 1 keyboard, 111.8ms\n","Speed: 4.0ms preprocess, 111.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 125.5ms\n","Speed: 3.9ms preprocess, 125.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 3 tvs, 9 laptops, 1 keyboard, 104.9ms\n","Speed: 4.5ms preprocess, 104.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 3 tvs, 11 laptops, 1 keyboard, 107.5ms\n","Speed: 3.9ms preprocess, 107.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 3 tvs, 11 laptops, 1 keyboard, 145.2ms\n","Speed: 5.9ms preprocess, 145.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 3 chairs, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 108.3ms\n","Speed: 5.3ms preprocess, 108.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 110.0ms\n","Speed: 5.7ms preprocess, 110.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 131.7ms\n","Speed: 4.5ms preprocess, 131.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 119.8ms\n","Speed: 6.4ms preprocess, 119.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 124.5ms\n","Speed: 5.0ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 116.6ms\n","Speed: 5.0ms preprocess, 116.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 130.1ms\n","Speed: 6.6ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 115.5ms\n","Speed: 6.6ms preprocess, 115.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 116.9ms\n","Speed: 5.3ms preprocess, 116.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 125.1ms\n","Speed: 5.1ms preprocess, 125.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 112.3ms\n","Speed: 4.5ms preprocess, 112.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 121.4ms\n","Speed: 5.3ms preprocess, 121.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 122.1ms\n","Speed: 4.7ms preprocess, 122.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 15 laptops, 1 keyboard, 116.9ms\n","Speed: 5.4ms preprocess, 116.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 121.3ms\n","Speed: 3.9ms preprocess, 121.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 120.5ms\n","Speed: 6.0ms preprocess, 120.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 12 laptops, 1 keyboard, 122.5ms\n","Speed: 5.5ms preprocess, 122.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 127.0ms\n","Speed: 4.8ms preprocess, 127.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 121.8ms\n","Speed: 3.9ms preprocess, 121.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 12 laptops, 1 keyboard, 115.3ms\n","Speed: 5.2ms preprocess, 115.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 116.3ms\n","Speed: 5.0ms preprocess, 116.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 110.1ms\n","Speed: 5.1ms preprocess, 110.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 111.5ms\n","Speed: 3.8ms preprocess, 111.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 104.5ms\n","Speed: 3.0ms preprocess, 104.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 118.6ms\n","Speed: 2.9ms preprocess, 118.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 102.3ms\n","Speed: 3.7ms preprocess, 102.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 106.8ms\n","Speed: 3.5ms preprocess, 106.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 103.7ms\n","Speed: 4.9ms preprocess, 103.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 101.0ms\n","Speed: 4.6ms preprocess, 101.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 104.4ms\n","Speed: 3.8ms preprocess, 104.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 109.6ms\n","Speed: 3.0ms preprocess, 109.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 120.0ms\n","Speed: 4.7ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 128.0ms\n","Speed: 5.1ms preprocess, 128.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 110.3ms\n","Speed: 5.4ms preprocess, 110.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 121.0ms\n","Speed: 3.9ms preprocess, 121.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 117.9ms\n","Speed: 5.9ms preprocess, 117.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 112.5ms\n","Speed: 5.4ms preprocess, 112.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 cups, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 111.8ms\n","Speed: 4.9ms preprocess, 111.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 cups, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 107.8ms\n","Speed: 3.5ms preprocess, 107.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 cups, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 115.0ms\n","Speed: 4.3ms preprocess, 115.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 cups, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 100.7ms\n","Speed: 4.2ms preprocess, 100.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 cups, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 103.6ms\n","Speed: 4.6ms preprocess, 103.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 cups, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 110.3ms\n","Speed: 3.2ms preprocess, 110.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 cups, 2 chairs, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 107.3ms\n","Speed: 4.7ms preprocess, 107.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 104.5ms\n","Speed: 3.2ms preprocess, 104.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 103.7ms\n","Speed: 4.9ms preprocess, 103.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 109.4ms\n","Speed: 3.6ms preprocess, 109.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 115.2ms\n","Speed: 4.3ms preprocess, 115.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 102.9ms\n","Speed: 3.8ms preprocess, 102.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 101.9ms\n","Speed: 4.3ms preprocess, 101.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 2 chairs, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 124.2ms\n","Speed: 3.4ms preprocess, 124.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 2 cups, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 108.4ms\n","Speed: 5.5ms preprocess, 108.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 2 cups, 2 chairs, 1 couch, 7 tvs, 9 laptops, 1 keyboard, 102.8ms\n","Speed: 4.3ms preprocess, 102.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 2 cups, 3 chairs, 1 couch, 8 tvs, 9 laptops, 141.9ms\n","Speed: 4.1ms preprocess, 141.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 bottle, 3 cups, 2 chairs, 1 couch, 9 tvs, 11 laptops, 134.1ms\n","Speed: 3.9ms preprocess, 134.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 12 laptops, 1 keyboard, 136.7ms\n","Speed: 2.8ms preprocess, 136.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 12 laptops, 1 keyboard, 127.9ms\n","Speed: 3.7ms preprocess, 127.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 8 tvs, 11 laptops, 1 keyboard, 172.9ms\n","Speed: 3.0ms preprocess, 172.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 141.8ms\n","Speed: 8.0ms preprocess, 141.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 11 laptops, 1 keyboard, 138.3ms\n","Speed: 3.1ms preprocess, 138.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 11 laptops, 1 keyboard, 155.6ms\n","Speed: 7.1ms preprocess, 155.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 140.9ms\n","Speed: 7.9ms preprocess, 140.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 13 laptops, 1 keyboard, 110.3ms\n","Speed: 3.7ms preprocess, 110.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 104.3ms\n","Speed: 2.9ms preprocess, 104.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 12 laptops, 1 keyboard, 124.7ms\n","Speed: 4.1ms preprocess, 124.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 9 laptops, 1 keyboard, 105.8ms\n","Speed: 4.0ms preprocess, 105.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 102.0ms\n","Speed: 3.9ms preprocess, 102.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 114.5ms\n","Speed: 3.7ms preprocess, 114.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 111.7ms\n","Speed: 4.0ms preprocess, 111.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 115.9ms\n","Speed: 5.7ms preprocess, 115.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 109.1ms\n","Speed: 4.9ms preprocess, 109.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 110.6ms\n","Speed: 3.4ms preprocess, 110.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 9 laptops, 1 keyboard, 117.2ms\n","Speed: 5.5ms preprocess, 117.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 100.7ms\n","Speed: 3.5ms preprocess, 100.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 100.8ms\n","Speed: 4.1ms preprocess, 100.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 107.2ms\n","Speed: 4.3ms preprocess, 107.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 113.7ms\n","Speed: 4.1ms preprocess, 113.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 117.3ms\n","Speed: 4.4ms preprocess, 117.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 11 laptops, 1 keyboard, 114.5ms\n","Speed: 5.1ms preprocess, 114.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 1 couch, 8 tvs, 11 laptops, 1 keyboard, 113.2ms\n","Speed: 4.5ms preprocess, 113.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 10 laptops, 1 keyboard, 117.8ms\n","Speed: 8.9ms preprocess, 117.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 13 laptops, 1 keyboard, 113.2ms\n","Speed: 4.7ms preprocess, 113.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 117.6ms\n","Speed: 5.2ms preprocess, 117.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 12 laptops, 1 keyboard, 112.6ms\n","Speed: 3.5ms preprocess, 112.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 11 laptops, 1 keyboard, 133.7ms\n","Speed: 3.8ms preprocess, 133.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 13 laptops, 1 keyboard, 114.7ms\n","Speed: 5.3ms preprocess, 114.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 12 laptops, 1 keyboard, 130.0ms\n","Speed: 5.6ms preprocess, 130.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 11 laptops, 1 keyboard, 124.5ms\n","Speed: 4.6ms preprocess, 124.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 9 tvs, 12 laptops, 1 keyboard, 110.5ms\n","Speed: 5.4ms preprocess, 110.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 13 laptops, 1 keyboard, 108.0ms\n","Speed: 5.4ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 12 laptops, 1 keyboard, 118.1ms\n","Speed: 7.1ms preprocess, 118.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 13 laptops, 1 keyboard, 123.2ms\n","Speed: 3.8ms preprocess, 123.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 13 laptops, 1 keyboard, 131.2ms\n","Speed: 7.5ms preprocess, 131.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 13 laptops, 1 keyboard, 122.0ms\n","Speed: 4.8ms preprocess, 122.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 13 laptops, 1 keyboard, 119.6ms\n","Speed: 4.9ms preprocess, 119.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 12 laptops, 1 keyboard, 127.7ms\n","Speed: 3.8ms preprocess, 127.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 7 tvs, 12 laptops, 1 keyboard, 122.7ms\n","Speed: 5.0ms preprocess, 122.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 12 laptops, 1 keyboard, 124.4ms\n","Speed: 5.2ms preprocess, 124.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 bottle, 1 cup, 1 chair, 1 couch, 8 tvs, 12 laptops, 1 keyboard, 123.0ms\n","Speed: 5.0ms preprocess, 123.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 8 tvs, 13 laptops, 1 keyboard, 106.0ms\n","Speed: 2.9ms preprocess, 106.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 13 laptops, 1 keyboard, 100.3ms\n","Speed: 4.3ms preprocess, 100.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 15 laptops, 1 keyboard, 101.9ms\n","Speed: 5.4ms preprocess, 101.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 13 laptops, 1 keyboard, 97.1ms\n","Speed: 4.3ms preprocess, 97.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 14 laptops, 1 keyboard, 109.4ms\n","Speed: 3.0ms preprocess, 109.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 16 laptops, 1 keyboard, 100.5ms\n","Speed: 4.1ms preprocess, 100.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 14 laptops, 1 keyboard, 102.6ms\n","Speed: 2.9ms preprocess, 102.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 15 laptops, 1 keyboard, 106.1ms\n","Speed: 3.9ms preprocess, 106.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 13 laptops, 1 keyboard, 106.1ms\n","Speed: 3.8ms preprocess, 106.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 9 tvs, 12 laptops, 1 keyboard, 107.0ms\n","Speed: 6.1ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 8 tvs, 13 laptops, 1 keyboard, 130.7ms\n","Speed: 4.7ms preprocess, 130.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 8 tvs, 12 laptops, 1 keyboard, 110.6ms\n","Speed: 4.4ms preprocess, 110.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 13 laptops, 1 keyboard, 120.6ms\n","Speed: 4.4ms preprocess, 120.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 9 tvs, 13 laptops, 1 keyboard, 121.2ms\n","Speed: 3.9ms preprocess, 121.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 12 laptops, 1 keyboard, 116.4ms\n","Speed: 6.1ms preprocess, 116.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 14 laptops, 1 keyboard, 104.9ms\n","Speed: 5.2ms preprocess, 104.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 14 laptops, 1 keyboard, 117.7ms\n","Speed: 4.4ms preprocess, 117.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 13 laptops, 1 keyboard, 103.5ms\n","Speed: 3.3ms preprocess, 103.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 12 laptops, 1 keyboard, 108.1ms\n","Speed: 5.0ms preprocess, 108.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 101.2ms\n","Speed: 3.9ms preprocess, 101.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 108.2ms\n","Speed: 4.2ms preprocess, 108.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 11 laptops, 1 keyboard, 120.7ms\n","Speed: 3.9ms preprocess, 120.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 11 laptops, 1 keyboard, 103.8ms\n","Speed: 4.5ms preprocess, 103.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 11 laptops, 1 keyboard, 101.5ms\n","Speed: 3.8ms preprocess, 101.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 13 laptops, 1 keyboard, 103.2ms\n","Speed: 4.3ms preprocess, 103.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 9 tvs, 10 laptops, 1 keyboard, 102.1ms\n","Speed: 2.9ms preprocess, 102.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 11 laptops, 1 keyboard, 110.1ms\n","Speed: 4.0ms preprocess, 110.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 8 tvs, 13 laptops, 1 keyboard, 102.5ms\n","Speed: 3.8ms preprocess, 102.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 11 laptops, 1 keyboard, 106.5ms\n","Speed: 4.4ms preprocess, 106.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 108.6ms\n","Speed: 3.0ms preprocess, 108.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 110.6ms\n","Speed: 6.4ms preprocess, 110.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 107.5ms\n","Speed: 3.4ms preprocess, 107.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 120.1ms\n","Speed: 4.6ms preprocess, 120.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 12 laptops, 1 keyboard, 104.0ms\n","Speed: 3.6ms preprocess, 104.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 12 laptops, 1 keyboard, 116.7ms\n","Speed: 3.4ms preprocess, 116.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 11 laptops, 1 keyboard, 121.5ms\n","Speed: 6.2ms preprocess, 121.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 119.2ms\n","Speed: 5.8ms preprocess, 119.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 113.4ms\n","Speed: 3.9ms preprocess, 113.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 16 laptops, 1 keyboard, 119.7ms\n","Speed: 4.5ms preprocess, 119.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 15 laptops, 1 keyboard, 164.2ms\n","Speed: 5.7ms preprocess, 164.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 14 laptops, 1 keyboard, 160.5ms\n","Speed: 10.8ms preprocess, 160.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 15 laptops, 1 keyboard, 156.7ms\n","Speed: 4.3ms preprocess, 156.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 16 laptops, 1 keyboard, 170.0ms\n","Speed: 9.2ms preprocess, 170.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 17 laptops, 1 keyboard, 187.2ms\n","Speed: 8.5ms preprocess, 187.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 18 laptops, 1 keyboard, 149.0ms\n","Speed: 5.7ms preprocess, 149.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 16 laptops, 1 keyboard, 165.2ms\n","Speed: 4.1ms preprocess, 165.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 17 laptops, 1 keyboard, 130.8ms\n","Speed: 5.2ms preprocess, 130.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 16 laptops, 1 keyboard, 99.5ms\n","Speed: 4.0ms preprocess, 99.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 15 laptops, 1 keyboard, 117.7ms\n","Speed: 4.4ms preprocess, 117.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 17 laptops, 1 keyboard, 104.0ms\n","Speed: 3.2ms preprocess, 104.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 15 laptops, 1 keyboard, 102.7ms\n","Speed: 4.6ms preprocess, 102.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 16 laptops, 1 keyboard, 103.3ms\n","Speed: 4.3ms preprocess, 103.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 19 laptops, 1 keyboard, 112.5ms\n","Speed: 4.3ms preprocess, 112.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 19 laptops, 1 keyboard, 106.3ms\n","Speed: 3.9ms preprocess, 106.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 17 laptops, 1 keyboard, 99.7ms\n","Speed: 3.8ms preprocess, 99.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 16 laptops, 1 keyboard, 102.2ms\n","Speed: 4.9ms preprocess, 102.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 16 laptops, 1 keyboard, 103.9ms\n","Speed: 3.9ms preprocess, 103.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 17 laptops, 1 keyboard, 121.8ms\n","Speed: 3.1ms preprocess, 121.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 16 laptops, 1 keyboard, 99.1ms\n","Speed: 3.8ms preprocess, 99.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 17 laptops, 1 keyboard, 106.4ms\n","Speed: 3.0ms preprocess, 106.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 18 laptops, 1 keyboard, 101.4ms\n","Speed: 4.1ms preprocess, 101.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 17 laptops, 1 keyboard, 109.1ms\n","Speed: 3.3ms preprocess, 109.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 17 laptops, 1 keyboard, 105.5ms\n","Speed: 3.0ms preprocess, 105.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 17 laptops, 1 keyboard, 107.7ms\n","Speed: 4.1ms preprocess, 107.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 16 laptops, 1 keyboard, 104.1ms\n","Speed: 4.1ms preprocess, 104.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 15 laptops, 1 keyboard, 117.6ms\n","Speed: 2.9ms preprocess, 117.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 15 laptops, 1 keyboard, 118.9ms\n","Speed: 4.1ms preprocess, 118.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 16 laptops, 1 keyboard, 103.5ms\n","Speed: 5.6ms preprocess, 103.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 16 laptops, 1 keyboard, 106.5ms\n","Speed: 4.1ms preprocess, 106.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 16 laptops, 1 keyboard, 112.1ms\n","Speed: 15.4ms preprocess, 112.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 18 laptops, 1 keyboard, 112.4ms\n","Speed: 4.1ms preprocess, 112.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 15 laptops, 1 keyboard, 103.8ms\n","Speed: 7.3ms preprocess, 103.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 17 laptops, 1 keyboard, 104.1ms\n","Speed: 4.3ms preprocess, 104.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 18 laptops, 1 keyboard, 113.0ms\n","Speed: 3.2ms preprocess, 113.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 17 laptops, 1 keyboard, 97.6ms\n","Speed: 4.1ms preprocess, 97.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 18 laptops, 1 keyboard, 100.4ms\n","Speed: 2.6ms preprocess, 100.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 17 laptops, 1 keyboard, 110.1ms\n","Speed: 18.0ms preprocess, 110.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 17 laptops, 1 keyboard, 112.4ms\n","Speed: 3.6ms preprocess, 112.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 17 laptops, 1 keyboard, 105.3ms\n","Speed: 5.1ms preprocess, 105.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 18 laptops, 1 keyboard, 107.3ms\n","Speed: 6.4ms preprocess, 107.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 18 laptops, 1 keyboard, 111.4ms\n","Speed: 5.2ms preprocess, 111.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 16 laptops, 1 keyboard, 147.4ms\n","Speed: 4.1ms preprocess, 147.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 16 laptops, 1 keyboard, 113.3ms\n","Speed: 5.4ms preprocess, 113.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 17 laptops, 1 keyboard, 111.8ms\n","Speed: 5.9ms preprocess, 111.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 16 laptops, 1 keyboard, 104.1ms\n","Speed: 4.0ms preprocess, 104.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 15 laptops, 1 keyboard, 108.8ms\n","Speed: 3.4ms preprocess, 108.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 16 laptops, 1 keyboard, 102.6ms\n","Speed: 4.0ms preprocess, 102.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 16 laptops, 1 keyboard, 104.4ms\n","Speed: 2.9ms preprocess, 104.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 13 laptops, 1 keyboard, 102.0ms\n","Speed: 4.0ms preprocess, 102.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 14 laptops, 1 keyboard, 111.4ms\n","Speed: 3.6ms preprocess, 111.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 13 laptops, 1 keyboard, 102.7ms\n","Speed: 4.1ms preprocess, 102.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 14 laptops, 1 keyboard, 104.2ms\n","Speed: 3.8ms preprocess, 104.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 14 laptops, 1 keyboard, 106.9ms\n","Speed: 3.9ms preprocess, 106.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 14 laptops, 1 keyboard, 103.4ms\n","Speed: 3.0ms preprocess, 103.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 98.9ms\n","Speed: 4.9ms preprocess, 98.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 13 laptops, 1 keyboard, 100.3ms\n","Speed: 3.2ms preprocess, 100.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 105.1ms\n","Speed: 4.7ms preprocess, 105.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 126.3ms\n","Speed: 4.3ms preprocess, 126.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 102.2ms\n","Speed: 6.1ms preprocess, 102.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 112.0ms\n","Speed: 4.4ms preprocess, 112.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 12 laptops, 1 keyboard, 99.6ms\n","Speed: 3.4ms preprocess, 99.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 14 laptops, 1 keyboard, 105.9ms\n","Speed: 3.8ms preprocess, 105.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 14 laptops, 1 keyboard, 99.9ms\n","Speed: 4.7ms preprocess, 99.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 12 laptops, 1 keyboard, 104.4ms\n","Speed: 3.6ms preprocess, 104.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 12 laptops, 1 keyboard, 95.0ms\n","Speed: 5.5ms preprocess, 95.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 107.9ms\n","Speed: 4.7ms preprocess, 107.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 12 laptops, 1 keyboard, 107.0ms\n","Speed: 4.3ms preprocess, 107.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 112.8ms\n","Speed: 3.8ms preprocess, 112.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 103.6ms\n","Speed: 6.0ms preprocess, 103.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 108.8ms\n","Speed: 3.2ms preprocess, 108.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 99.4ms\n","Speed: 4.1ms preprocess, 99.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 102.5ms\n","Speed: 4.1ms preprocess, 102.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 101.9ms\n","Speed: 4.2ms preprocess, 101.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 13 laptops, 1 keyboard, 120.2ms\n","Speed: 5.5ms preprocess, 120.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 111.4ms\n","Speed: 4.1ms preprocess, 111.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 102.2ms\n","Speed: 5.1ms preprocess, 102.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 102.5ms\n","Speed: 4.0ms preprocess, 102.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 103.0ms\n","Speed: 3.0ms preprocess, 103.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 109.2ms\n","Speed: 2.9ms preprocess, 109.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 106.2ms\n","Speed: 3.5ms preprocess, 106.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 7 laptops, 1 keyboard, 107.0ms\n","Speed: 4.7ms preprocess, 107.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 7 laptops, 1 keyboard, 115.3ms\n","Speed: 3.5ms preprocess, 115.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 111.9ms\n","Speed: 4.3ms preprocess, 111.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 107.9ms\n","Speed: 4.7ms preprocess, 107.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 122.4ms\n","Speed: 4.2ms preprocess, 122.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 108.2ms\n","Speed: 3.4ms preprocess, 108.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 9 laptops, 1 keyboard, 124.7ms\n","Speed: 4.5ms preprocess, 124.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 7 laptops, 1 keyboard, 153.0ms\n","Speed: 4.1ms preprocess, 153.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 160.8ms\n","Speed: 4.0ms preprocess, 160.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 6 laptops, 1 keyboard, 175.8ms\n","Speed: 2.8ms preprocess, 175.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 6 laptops, 1 keyboard, 138.8ms\n","Speed: 6.3ms preprocess, 138.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 139.8ms\n","Speed: 4.3ms preprocess, 139.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 140.5ms\n","Speed: 4.1ms preprocess, 140.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 148.4ms\n","Speed: 3.4ms preprocess, 148.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 133.5ms\n","Speed: 7.5ms preprocess, 133.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 104.5ms\n","Speed: 4.2ms preprocess, 104.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 110.7ms\n","Speed: 10.0ms preprocess, 110.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 8 laptops, 1 keyboard, 125.4ms\n","Speed: 3.1ms preprocess, 125.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 1 potted plant, 7 tvs, 7 laptops, 1 keyboard, 116.3ms\n","Speed: 5.0ms preprocess, 116.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 6 laptops, 1 keyboard, 117.0ms\n","Speed: 5.8ms preprocess, 117.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 7 tvs, 7 laptops, 1 keyboard, 114.0ms\n","Speed: 5.8ms preprocess, 114.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 125.7ms\n","Speed: 3.6ms preprocess, 125.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 106.8ms\n","Speed: 6.7ms preprocess, 106.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 136.0ms\n","Speed: 4.1ms preprocess, 136.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 111.5ms\n","Speed: 6.2ms preprocess, 111.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 3 chairs, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 109.9ms\n","Speed: 4.4ms preprocess, 109.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 8 laptops, 1 keyboard, 104.9ms\n","Speed: 3.9ms preprocess, 104.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 103.4ms\n","Speed: 4.2ms preprocess, 103.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 101.5ms\n","Speed: 3.8ms preprocess, 101.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 103.8ms\n","Speed: 4.5ms preprocess, 103.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 113.6ms\n","Speed: 5.4ms preprocess, 113.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 112.9ms\n","Speed: 5.6ms preprocess, 112.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 111.0ms\n","Speed: 4.3ms preprocess, 111.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 119.0ms\n","Speed: 4.4ms preprocess, 119.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 107.9ms\n","Speed: 4.7ms preprocess, 107.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 103.6ms\n","Speed: 5.7ms preprocess, 103.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 107.2ms\n","Speed: 5.2ms preprocess, 107.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 126.7ms\n","Speed: 4.3ms preprocess, 126.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 114.3ms\n","Speed: 4.3ms preprocess, 114.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 109.7ms\n","Speed: 5.5ms preprocess, 109.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 117.1ms\n","Speed: 4.9ms preprocess, 117.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 115.1ms\n","Speed: 4.8ms preprocess, 115.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 111.7ms\n","Speed: 4.9ms preprocess, 111.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 115.6ms\n","Speed: 6.7ms preprocess, 115.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 104.7ms\n","Speed: 5.3ms preprocess, 104.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 104.6ms\n","Speed: 3.3ms preprocess, 104.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 120.5ms\n","Speed: 6.0ms preprocess, 120.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 122.2ms\n","Speed: 3.7ms preprocess, 122.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 97.0ms\n","Speed: 4.7ms preprocess, 97.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 11 laptops, 1 keyboard, 106.6ms\n","Speed: 2.8ms preprocess, 106.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 12 laptops, 1 keyboard, 106.3ms\n","Speed: 5.0ms preprocess, 106.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 119.0ms\n","Speed: 3.7ms preprocess, 119.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 11 laptops, 1 keyboard, 107.8ms\n","Speed: 4.5ms preprocess, 107.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 117.5ms\n","Speed: 3.9ms preprocess, 117.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 110.6ms\n","Speed: 4.5ms preprocess, 110.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 106.7ms\n","Speed: 6.6ms preprocess, 106.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 105.6ms\n","Speed: 5.5ms preprocess, 105.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 115.5ms\n","Speed: 4.0ms preprocess, 115.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 115.1ms\n","Speed: 4.9ms preprocess, 115.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 121.5ms\n","Speed: 5.3ms preprocess, 121.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 123.1ms\n","Speed: 5.6ms preprocess, 123.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 120.3ms\n","Speed: 3.7ms preprocess, 120.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 14 laptops, 1 keyboard, 132.5ms\n","Speed: 6.4ms preprocess, 132.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 14 laptops, 1 keyboard, 150.3ms\n","Speed: 6.3ms preprocess, 150.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 111.1ms\n","Speed: 5.8ms preprocess, 111.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 119.4ms\n","Speed: 4.8ms preprocess, 119.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 147.5ms\n","Speed: 5.0ms preprocess, 147.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 118.1ms\n","Speed: 5.0ms preprocess, 118.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 138.2ms\n","Speed: 5.7ms preprocess, 138.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 15 laptops, 1 keyboard, 142.9ms\n","Speed: 3.6ms preprocess, 142.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 14 laptops, 1 keyboard, 110.1ms\n","Speed: 6.4ms preprocess, 110.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 17 laptops, 1 keyboard, 107.3ms\n","Speed: 6.5ms preprocess, 107.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 15 laptops, 1 keyboard, 114.4ms\n","Speed: 6.9ms preprocess, 114.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 1 couch, 5 tvs, 14 laptops, 1 keyboard, 109.6ms\n","Speed: 5.4ms preprocess, 109.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 5 tvs, 15 laptops, 1 keyboard, 103.3ms\n","Speed: 5.6ms preprocess, 103.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 4 tvs, 12 laptops, 1 keyboard, 104.9ms\n","Speed: 4.1ms preprocess, 104.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 6 tvs, 13 laptops, 1 keyboard, 119.8ms\n","Speed: 4.6ms preprocess, 119.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 2 chairs, 7 tvs, 15 laptops, 1 keyboard, 115.3ms\n","Speed: 5.3ms preprocess, 115.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 7 tvs, 14 laptops, 1 keyboard, 112.4ms\n","Speed: 7.2ms preprocess, 112.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 cup, 2 chairs, 6 tvs, 13 laptops, 1 keyboard, 120.9ms\n","Speed: 3.8ms preprocess, 120.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 110.6ms\n","Speed: 5.2ms preprocess, 110.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 114.7ms\n","Speed: 5.0ms preprocess, 114.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 119.1ms\n","Speed: 5.0ms preprocess, 119.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 118.0ms\n","Speed: 4.5ms preprocess, 118.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 120.7ms\n","Speed: 6.1ms preprocess, 120.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 114.9ms\n","Speed: 4.7ms preprocess, 114.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 102.0ms\n","Speed: 4.5ms preprocess, 102.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 115.4ms\n","Speed: 8.8ms preprocess, 115.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 122.4ms\n","Speed: 4.3ms preprocess, 122.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 155.9ms\n","Speed: 5.1ms preprocess, 155.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 9 laptops, 1 keyboard, 158.8ms\n","Speed: 6.4ms preprocess, 158.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 135.1ms\n","Speed: 4.2ms preprocess, 135.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 126.1ms\n","Speed: 4.1ms preprocess, 126.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 127.8ms\n","Speed: 3.2ms preprocess, 127.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 134.3ms\n","Speed: 4.9ms preprocess, 134.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 160.9ms\n","Speed: 6.1ms preprocess, 160.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 146.3ms\n","Speed: 4.6ms preprocess, 146.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 105.5ms\n","Speed: 3.4ms preprocess, 105.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 111.9ms\n","Speed: 5.2ms preprocess, 111.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 113.9ms\n","Speed: 6.8ms preprocess, 113.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 122.9ms\n","Speed: 6.8ms preprocess, 122.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 119.6ms\n","Speed: 4.0ms preprocess, 119.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 116.8ms\n","Speed: 5.7ms preprocess, 116.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 119.3ms\n","Speed: 5.4ms preprocess, 119.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 118.5ms\n","Speed: 5.0ms preprocess, 118.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 123.1ms\n","Speed: 3.9ms preprocess, 123.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 106.9ms\n","Speed: 6.3ms preprocess, 106.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 114.7ms\n","Speed: 4.8ms preprocess, 114.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 104.0ms\n","Speed: 4.3ms preprocess, 104.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 106.5ms\n","Speed: 4.8ms preprocess, 106.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 112.0ms\n","Speed: 4.1ms preprocess, 112.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 109.6ms\n","Speed: 4.8ms preprocess, 109.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 3 tvs, 10 laptops, 1 keyboard, 99.4ms\n","Speed: 4.2ms preprocess, 99.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 107.0ms\n","Speed: 3.0ms preprocess, 107.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 103.2ms\n","Speed: 4.0ms preprocess, 103.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 103.0ms\n","Speed: 3.7ms preprocess, 103.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 104.5ms\n","Speed: 3.9ms preprocess, 104.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 1 cell phone, 130.4ms\n","Speed: 3.2ms preprocess, 130.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 7 tvs, 10 laptops, 1 keyboard, 105.3ms\n","Speed: 4.7ms preprocess, 105.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 1 cell phone, 108.7ms\n","Speed: 6.9ms preprocess, 108.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 1 cell phone, 103.3ms\n","Speed: 4.0ms preprocess, 103.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 10 laptops, 1 keyboard, 1 cell phone, 109.3ms\n","Speed: 4.0ms preprocess, 109.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 1 cell phone, 113.3ms\n","Speed: 5.6ms preprocess, 113.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 9 laptops, 1 keyboard, 1 cell phone, 105.3ms\n","Speed: 5.2ms preprocess, 105.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 1 cell phone, 105.1ms\n","Speed: 5.0ms preprocess, 105.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 126.9ms\n","Speed: 2.7ms preprocess, 126.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 101.8ms\n","Speed: 4.1ms preprocess, 101.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 15 laptops, 1 keyboard, 110.3ms\n","Speed: 4.0ms preprocess, 110.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 95.5ms\n","Speed: 4.8ms preprocess, 95.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 13 laptops, 1 keyboard, 106.9ms\n","Speed: 2.9ms preprocess, 106.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 1 cell phone, 114.0ms\n","Speed: 3.9ms preprocess, 114.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 6 tvs, 11 laptops, 1 keyboard, 101.3ms\n","Speed: 3.6ms preprocess, 101.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 6 tvs, 11 laptops, 1 keyboard, 98.4ms\n","Speed: 5.4ms preprocess, 98.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 96.3ms\n","Speed: 2.9ms preprocess, 96.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 6 tvs, 11 laptops, 1 keyboard, 101.1ms\n","Speed: 3.5ms preprocess, 101.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 103.0ms\n","Speed: 5.7ms preprocess, 103.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 9 laptops, 1 keyboard, 106.2ms\n","Speed: 4.9ms preprocess, 106.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 11 laptops, 1 keyboard, 118.8ms\n","Speed: 3.2ms preprocess, 118.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 3 chairs, 3 tvs, 10 laptops, 1 keyboard, 112.4ms\n","Speed: 4.5ms preprocess, 112.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 3 tvs, 11 laptops, 1 keyboard, 113.9ms\n","Speed: 5.0ms preprocess, 113.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 3 tvs, 10 laptops, 1 keyboard, 139.2ms\n","Speed: 4.4ms preprocess, 139.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 4 tvs, 11 laptops, 1 keyboard, 113.6ms\n","Speed: 3.8ms preprocess, 113.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 4 tvs, 11 laptops, 1 keyboard, 114.0ms\n","Speed: 6.5ms preprocess, 114.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 4 tvs, 12 laptops, 1 keyboard, 118.1ms\n","Speed: 7.1ms preprocess, 118.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 3 tvs, 12 laptops, 1 keyboard, 114.0ms\n","Speed: 5.2ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 4 tvs, 11 laptops, 1 keyboard, 129.9ms\n","Speed: 4.9ms preprocess, 129.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 4 tvs, 12 laptops, 1 keyboard, 104.2ms\n","Speed: 6.3ms preprocess, 104.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 120.1ms\n","Speed: 5.8ms preprocess, 120.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 100.4ms\n","Speed: 3.9ms preprocess, 100.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 3 tvs, 13 laptops, 1 keyboard, 101.6ms\n","Speed: 3.3ms preprocess, 101.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 3 tvs, 13 laptops, 1 keyboard, 105.5ms\n","Speed: 4.5ms preprocess, 105.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 15 laptops, 1 keyboard, 99.5ms\n","Speed: 4.1ms preprocess, 99.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 2 chairs, 1 couch, 2 tvs, 14 laptops, 1 keyboard, 96.9ms\n","Speed: 3.9ms preprocess, 96.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 chair, 1 couch, 4 tvs, 15 laptops, 1 keyboard, 103.9ms\n","Speed: 3.2ms preprocess, 103.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 chair, 1 couch, 3 tvs, 14 laptops, 1 keyboard, 108.8ms\n","Speed: 4.3ms preprocess, 108.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 chair, 3 tvs, 13 laptops, 1 keyboard, 123.0ms\n","Speed: 3.0ms preprocess, 123.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 chair, 4 tvs, 13 laptops, 1 keyboard, 105.4ms\n","Speed: 4.5ms preprocess, 105.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 chair, 4 tvs, 15 laptops, 1 keyboard, 108.9ms\n","Speed: 3.2ms preprocess, 108.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 15 persons, 2 chairs, 5 tvs, 14 laptops, 1 keyboard, 108.7ms\n","Speed: 4.0ms preprocess, 108.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 chair, 4 tvs, 14 laptops, 1 keyboard, 100.8ms\n","Speed: 3.9ms preprocess, 100.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 chairs, 4 tvs, 13 laptops, 1 keyboard, 104.2ms\n","Speed: 4.1ms preprocess, 104.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 4 tvs, 13 laptops, 1 keyboard, 109.8ms\n","Speed: 3.1ms preprocess, 109.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 chair, 4 tvs, 13 laptops, 1 keyboard, 117.9ms\n","Speed: 4.4ms preprocess, 117.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 4 tvs, 12 laptops, 1 keyboard, 112.5ms\n","Speed: 3.6ms preprocess, 112.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 chair, 4 tvs, 12 laptops, 1 keyboard, 94.4ms\n","Speed: 3.9ms preprocess, 94.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 4 tvs, 11 laptops, 1 keyboard, 107.8ms\n","Speed: 3.0ms preprocess, 107.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 4 tvs, 10 laptops, 1 keyboard, 103.4ms\n","Speed: 6.5ms preprocess, 103.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 103.9ms\n","Speed: 4.5ms preprocess, 103.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 4 tvs, 13 laptops, 1 keyboard, 99.3ms\n","Speed: 3.7ms preprocess, 99.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 4 tvs, 12 laptops, 1 keyboard, 109.0ms\n","Speed: 2.9ms preprocess, 109.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 4 tvs, 12 laptops, 1 keyboard, 107.4ms\n","Speed: 4.7ms preprocess, 107.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 1 cup, 1 chair, 4 tvs, 12 laptops, 1 keyboard, 100.1ms\n","Speed: 2.8ms preprocess, 100.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 4 tvs, 12 laptops, 1 keyboard, 113.5ms\n","Speed: 4.1ms preprocess, 113.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 3 tvs, 12 laptops, 1 keyboard, 99.9ms\n","Speed: 2.7ms preprocess, 99.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 3 tvs, 12 laptops, 1 keyboard, 103.1ms\n","Speed: 3.8ms preprocess, 103.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 2 tvs, 12 laptops, 1 keyboard, 129.1ms\n","Speed: 3.8ms preprocess, 129.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 3 tvs, 13 laptops, 1 keyboard, 139.6ms\n","Speed: 3.9ms preprocess, 139.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 3 tvs, 12 laptops, 1 keyboard, 138.7ms\n","Speed: 3.3ms preprocess, 138.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 chair, 3 tvs, 10 laptops, 1 keyboard, 182.3ms\n","Speed: 3.8ms preprocess, 182.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 3 tvs, 11 laptops, 1 keyboard, 129.4ms\n","Speed: 6.0ms preprocess, 129.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 chair, 1 couch, 3 tvs, 11 laptops, 1 keyboard, 125.9ms\n","Speed: 6.0ms preprocess, 125.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 chairs, 1 couch, 5 tvs, 10 laptops, 1 keyboard, 133.8ms\n","Speed: 3.0ms preprocess, 133.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 136.3ms\n","Speed: 6.7ms preprocess, 136.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 132.4ms\n","Speed: 5.6ms preprocess, 132.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 1 couch, 4 tvs, 13 laptops, 1 keyboard, 150.5ms\n","Speed: 5.2ms preprocess, 150.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 1 couch, 6 tvs, 12 laptops, 1 keyboard, 125.4ms\n","Speed: 4.5ms preprocess, 125.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 6 tvs, 12 laptops, 1 keyboard, 104.8ms\n","Speed: 4.2ms preprocess, 104.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 117.6ms\n","Speed: 3.3ms preprocess, 117.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 110.3ms\n","Speed: 4.5ms preprocess, 110.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 4 tvs, 14 laptops, 1 keyboard, 102.5ms\n","Speed: 2.9ms preprocess, 102.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 potted plant, 5 tvs, 12 laptops, 1 keyboard, 106.4ms\n","Speed: 4.2ms preprocess, 106.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 107.1ms\n","Speed: 4.1ms preprocess, 107.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 1 potted plant, 5 tvs, 10 laptops, 1 keyboard, 105.5ms\n","Speed: 4.7ms preprocess, 105.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 8 laptops, 1 keyboard, 1 cell phone, 118.4ms\n","Speed: 3.1ms preprocess, 118.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 6 tvs, 10 laptops, 1 keyboard, 1 cell phone, 118.5ms\n","Speed: 4.0ms preprocess, 118.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 11 laptops, 1 keyboard, 1 cell phone, 106.3ms\n","Speed: 4.7ms preprocess, 106.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 1 cell phone, 103.4ms\n","Speed: 4.1ms preprocess, 103.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 98.9ms\n","Speed: 2.9ms preprocess, 98.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 105.1ms\n","Speed: 4.1ms preprocess, 105.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 6 tvs, 11 laptops, 1 keyboard, 1 cell phone, 108.1ms\n","Speed: 4.4ms preprocess, 108.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 4 tvs, 10 laptops, 1 keyboard, 1 cell phone, 111.4ms\n","Speed: 4.1ms preprocess, 111.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 1 cell phone, 125.0ms\n","Speed: 3.2ms preprocess, 125.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 11 laptops, 1 keyboard, 1 cell phone, 102.1ms\n","Speed: 4.0ms preprocess, 102.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 1 cell phone, 101.5ms\n","Speed: 3.9ms preprocess, 101.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 6 tvs, 8 laptops, 1 keyboard, 1 cell phone, 102.2ms\n","Speed: 4.0ms preprocess, 102.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 chair, 6 tvs, 8 laptops, 1 keyboard, 1 cell phone, 102.5ms\n","Speed: 3.2ms preprocess, 102.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 1 chair, 6 tvs, 8 laptops, 1 keyboard, 1 cell phone, 101.7ms\n","Speed: 4.7ms preprocess, 101.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 chair, 3 tvs, 9 laptops, 1 keyboard, 100.8ms\n","Speed: 3.1ms preprocess, 100.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 chair, 4 tvs, 9 laptops, 1 keyboard, 96.3ms\n","Speed: 3.9ms preprocess, 96.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 4 tvs, 8 laptops, 1 keyboard, 112.0ms\n","Speed: 3.2ms preprocess, 112.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 7 laptops, 1 keyboard, 111.6ms\n","Speed: 5.0ms preprocess, 111.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 4 tvs, 7 laptops, 1 keyboard, 98.6ms\n","Speed: 4.1ms preprocess, 98.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 5 tvs, 8 laptops, 1 keyboard, 97.1ms\n","Speed: 4.1ms preprocess, 97.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 chair, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 97.7ms\n","Speed: 3.1ms preprocess, 97.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 96.8ms\n","Speed: 3.8ms preprocess, 96.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 102.0ms\n","Speed: 3.8ms preprocess, 102.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 99.5ms\n","Speed: 3.8ms preprocess, 99.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 chair, 1 couch, 5 tvs, 7 laptops, 1 keyboard, 102.6ms\n","Speed: 3.3ms preprocess, 102.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 5 tvs, 7 laptops, 1 keyboard, 116.1ms\n","Speed: 5.4ms preprocess, 116.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 1 couch, 6 tvs, 7 laptops, 1 keyboard, 97.3ms\n","Speed: 4.2ms preprocess, 97.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 5 tvs, 7 laptops, 1 keyboard, 99.6ms\n","Speed: 3.5ms preprocess, 99.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 8 laptops, 1 keyboard, 105.6ms\n","Speed: 3.5ms preprocess, 105.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 1 couch, 3 tvs, 8 laptops, 1 keyboard, 98.9ms\n","Speed: 3.0ms preprocess, 98.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 8 laptops, 1 keyboard, 100.9ms\n","Speed: 5.1ms preprocess, 100.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 10 laptops, 1 keyboard, 93.9ms\n","Speed: 3.6ms preprocess, 93.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 1 chair, 1 couch, 4 tvs, 10 laptops, 1 keyboard, 106.9ms\n","Speed: 2.7ms preprocess, 106.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 4 tvs, 10 laptops, 1 keyboard, 98.4ms\n","Speed: 4.6ms preprocess, 98.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 4 tvs, 9 laptops, 1 keyboard, 103.3ms\n","Speed: 4.7ms preprocess, 103.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 chair, 1 couch, 3 tvs, 10 laptops, 1 keyboard, 105.9ms\n","Speed: 4.4ms preprocess, 105.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 1 couch, 3 tvs, 11 laptops, 1 keyboard, 104.8ms\n","Speed: 3.1ms preprocess, 104.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 1 couch, 3 tvs, 11 laptops, 1 keyboard, 101.8ms\n","Speed: 5.1ms preprocess, 101.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 3 tvs, 11 laptops, 1 keyboard, 102.7ms\n","Speed: 4.4ms preprocess, 102.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 3 tvs, 10 laptops, 1 keyboard, 101.4ms\n","Speed: 5.0ms preprocess, 101.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 4 tvs, 12 laptops, 1 keyboard, 105.8ms\n","Speed: 3.6ms preprocess, 105.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 4 tvs, 12 laptops, 1 keyboard, 110.4ms\n","Speed: 4.5ms preprocess, 110.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 3 chairs, 1 couch, 4 tvs, 12 laptops, 1 keyboard, 125.8ms\n","Speed: 6.2ms preprocess, 125.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 3 chairs, 1 couch, 2 tvs, 13 laptops, 1 keyboard, 126.1ms\n","Speed: 7.3ms preprocess, 126.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 3 chairs, 1 couch, 2 tvs, 14 laptops, 1 keyboard, 118.5ms\n","Speed: 3.5ms preprocess, 118.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 1 couch, 2 tvs, 14 laptops, 1 keyboard, 119.9ms\n","Speed: 5.7ms preprocess, 119.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 3 chairs, 2 tvs, 13 laptops, 1 keyboard, 121.0ms\n","Speed: 4.8ms preprocess, 121.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 3 chairs, 2 tvs, 13 laptops, 1 keyboard, 114.9ms\n","Speed: 5.5ms preprocess, 114.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 3 chairs, 2 tvs, 13 laptops, 1 keyboard, 121.9ms\n","Speed: 3.8ms preprocess, 121.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 2 tvs, 13 laptops, 1 keyboard, 1 cell phone, 118.6ms\n","Speed: 3.8ms preprocess, 118.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 2 tvs, 14 laptops, 1 keyboard, 1 cell phone, 107.0ms\n","Speed: 3.8ms preprocess, 107.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 2 tvs, 15 laptops, 1 keyboard, 1 cell phone, 108.1ms\n","Speed: 4.1ms preprocess, 108.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 2 tvs, 14 laptops, 1 keyboard, 1 cell phone, 107.9ms\n","Speed: 3.5ms preprocess, 107.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 4 chairs, 2 tvs, 15 laptops, 1 keyboard, 1 cell phone, 103.8ms\n","Speed: 4.0ms preprocess, 103.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 4 chairs, 2 tvs, 15 laptops, 1 keyboard, 1 cell phone, 111.8ms\n","Speed: 3.4ms preprocess, 111.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 2 tvs, 15 laptops, 1 keyboard, 100.7ms\n","Speed: 4.1ms preprocess, 100.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 3 chairs, 2 tvs, 12 laptops, 1 keyboard, 105.7ms\n","Speed: 3.0ms preprocess, 105.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 3 tvs, 13 laptops, 1 keyboard, 1 cell phone, 115.4ms\n","Speed: 3.8ms preprocess, 115.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 4 chairs, 3 tvs, 13 laptops, 1 keyboard, 133.4ms\n","Speed: 4.2ms preprocess, 133.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 4 chairs, 3 tvs, 14 laptops, 1 keyboard, 109.6ms\n","Speed: 4.7ms preprocess, 109.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 3 chairs, 3 tvs, 14 laptops, 1 keyboard, 1 cell phone, 112.3ms\n","Speed: 4.4ms preprocess, 112.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 3 chairs, 3 tvs, 14 laptops, 1 keyboard, 1 cell phone, 112.4ms\n","Speed: 6.1ms preprocess, 112.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 3 tvs, 16 laptops, 1 keyboard, 109.1ms\n","Speed: 5.1ms preprocess, 109.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 3 chairs, 2 tvs, 15 laptops, 1 keyboard, 110.1ms\n","Speed: 4.7ms preprocess, 110.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 3 chairs, 2 tvs, 15 laptops, 1 keyboard, 1 cell phone, 117.4ms\n","Speed: 5.5ms preprocess, 117.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 3 chairs, 4 tvs, 13 laptops, 1 keyboard, 1 cell phone, 109.4ms\n","Speed: 3.8ms preprocess, 109.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 2 tvs, 13 laptops, 1 keyboard, 1 cell phone, 106.8ms\n","Speed: 4.6ms preprocess, 106.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 2 tvs, 14 laptops, 1 keyboard, 1 cell phone, 95.7ms\n","Speed: 4.6ms preprocess, 95.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 2 tvs, 15 laptops, 1 keyboard, 1 cell phone, 101.6ms\n","Speed: 3.8ms preprocess, 101.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 2 tvs, 14 laptops, 1 keyboard, 1 cell phone, 103.0ms\n","Speed: 3.9ms preprocess, 103.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 2 tvs, 13 laptops, 1 keyboard, 1 cell phone, 104.1ms\n","Speed: 3.7ms preprocess, 104.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 3 chairs, 2 tvs, 13 laptops, 1 keyboard, 1 cell phone, 109.5ms\n","Speed: 4.1ms preprocess, 109.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 2 tvs, 14 laptops, 1 keyboard, 1 cell phone, 154.7ms\n","Speed: 3.3ms preprocess, 154.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 3 chairs, 2 tvs, 14 laptops, 1 keyboard, 1 cell phone, 154.6ms\n","Speed: 3.7ms preprocess, 154.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 2 tvs, 12 laptops, 1 keyboard, 1 cell phone, 122.3ms\n","Speed: 3.8ms preprocess, 122.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 3 chairs, 2 tvs, 12 laptops, 1 keyboard, 1 cell phone, 125.5ms\n","Speed: 3.5ms preprocess, 125.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 2 tvs, 11 laptops, 1 keyboard, 1 cell phone, 139.2ms\n","Speed: 2.8ms preprocess, 139.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 2 tvs, 12 laptops, 1 keyboard, 1 cell phone, 175.0ms\n","Speed: 4.0ms preprocess, 175.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 3 chairs, 3 tvs, 11 laptops, 1 keyboard, 1 cell phone, 144.5ms\n","Speed: 6.9ms preprocess, 144.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 3 chairs, 3 tvs, 11 laptops, 1 keyboard, 1 cell phone, 148.8ms\n","Speed: 4.0ms preprocess, 148.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 3 tvs, 11 laptops, 1 keyboard, 1 cell phone, 118.5ms\n","Speed: 4.9ms preprocess, 118.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 3 chairs, 3 tvs, 12 laptops, 1 keyboard, 1 cell phone, 100.0ms\n","Speed: 4.0ms preprocess, 100.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 3 tvs, 11 laptops, 1 keyboard, 1 cell phone, 110.6ms\n","Speed: 4.0ms preprocess, 110.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 2 tvs, 12 laptops, 1 keyboard, 1 cell phone, 106.7ms\n","Speed: 4.8ms preprocess, 106.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 3 tvs, 12 laptops, 1 keyboard, 1 cell phone, 107.4ms\n","Speed: 2.8ms preprocess, 107.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 3 tvs, 11 laptops, 1 keyboard, 1 cell phone, 106.4ms\n","Speed: 4.9ms preprocess, 106.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 3 tvs, 11 laptops, 1 keyboard, 109.5ms\n","Speed: 3.0ms preprocess, 109.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 4 tvs, 11 laptops, 1 keyboard, 1 cell phone, 101.1ms\n","Speed: 4.0ms preprocess, 101.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 111.5ms\n","Speed: 3.0ms preprocess, 111.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 3 tvs, 11 laptops, 1 keyboard, 1 cell phone, 106.0ms\n","Speed: 4.9ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 4 tvs, 12 laptops, 1 keyboard, 1 cell phone, 99.0ms\n","Speed: 3.8ms preprocess, 99.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 4 tvs, 11 laptops, 1 keyboard, 1 cell phone, 100.5ms\n","Speed: 4.1ms preprocess, 100.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 4 tvs, 10 laptops, 1 keyboard, 107.4ms\n","Speed: 5.0ms preprocess, 107.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 4 tvs, 10 laptops, 1 keyboard, 1 cell phone, 111.3ms\n","Speed: 4.2ms preprocess, 111.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 4 tvs, 11 laptops, 1 keyboard, 1 cell phone, 100.0ms\n","Speed: 3.0ms preprocess, 100.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 5 tvs, 10 laptops, 1 keyboard, 1 cell phone, 110.7ms\n","Speed: 4.6ms preprocess, 110.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 4 tvs, 9 laptops, 1 keyboard, 1 cell phone, 130.8ms\n","Speed: 5.3ms preprocess, 130.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 4 tvs, 9 laptops, 1 keyboard, 1 cell phone, 117.1ms\n","Speed: 5.3ms preprocess, 117.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 4 tvs, 10 laptops, 1 keyboard, 1 cell phone, 116.3ms\n","Speed: 4.7ms preprocess, 116.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 chair, 4 tvs, 9 laptops, 1 keyboard, 1 cell phone, 122.5ms\n","Speed: 4.9ms preprocess, 122.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 chair, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 115.2ms\n","Speed: 18.8ms preprocess, 115.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 chair, 5 tvs, 10 laptops, 1 keyboard, 1 cell phone, 114.7ms\n","Speed: 5.9ms preprocess, 114.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 chair, 5 tvs, 10 laptops, 1 keyboard, 1 cell phone, 108.6ms\n","Speed: 6.4ms preprocess, 108.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 chair, 6 tvs, 9 laptops, 1 keyboard, 1 cell phone, 128.8ms\n","Speed: 5.1ms preprocess, 128.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 chair, 5 tvs, 9 laptops, 1 keyboard, 1 cell phone, 120.6ms\n","Speed: 4.3ms preprocess, 120.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 chair, 5 tvs, 10 laptops, 1 keyboard, 1 cell phone, 114.4ms\n","Speed: 6.1ms preprocess, 114.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 chair, 6 tvs, 11 laptops, 1 keyboard, 1 cell phone, 111.7ms\n","Speed: 4.8ms preprocess, 111.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 5 tvs, 10 laptops, 1 keyboard, 1 cell phone, 122.2ms\n","Speed: 4.8ms preprocess, 122.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 5 tvs, 10 laptops, 1 keyboard, 1 cell phone, 122.3ms\n","Speed: 3.5ms preprocess, 122.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 129.2ms\n","Speed: 5.8ms preprocess, 129.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 114.1ms\n","Speed: 3.1ms preprocess, 114.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 chair, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 112.6ms\n","Speed: 4.3ms preprocess, 112.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 104.6ms\n","Speed: 4.7ms preprocess, 104.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 107.6ms\n","Speed: 4.9ms preprocess, 107.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 chair, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 107.0ms\n","Speed: 6.7ms preprocess, 107.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 chair, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 97.3ms\n","Speed: 4.7ms preprocess, 97.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 1 chair, 5 tvs, 13 laptops, 1 keyboard, 1 cell phone, 114.7ms\n","Speed: 2.9ms preprocess, 114.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 chair, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 106.4ms\n","Speed: 4.5ms preprocess, 106.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 1 chair, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 115.2ms\n","Speed: 4.1ms preprocess, 115.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 1 chair, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 112.5ms\n","Speed: 5.1ms preprocess, 112.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 112.0ms\n","Speed: 4.1ms preprocess, 112.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 104.4ms\n","Speed: 3.8ms preprocess, 104.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 113.9ms\n","Speed: 4.9ms preprocess, 113.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 103.0ms\n","Speed: 4.9ms preprocess, 103.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 4 tvs, 11 laptops, 1 keyboard, 1 cell phone, 105.2ms\n","Speed: 5.0ms preprocess, 105.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 4 tvs, 11 laptops, 1 keyboard, 1 cell phone, 108.1ms\n","Speed: 4.6ms preprocess, 108.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 4 tvs, 12 laptops, 1 keyboard, 1 cell phone, 108.2ms\n","Speed: 4.2ms preprocess, 108.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 4 tvs, 12 laptops, 1 keyboard, 1 cell phone, 116.7ms\n","Speed: 5.8ms preprocess, 116.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 4 tvs, 12 laptops, 1 keyboard, 1 cell phone, 107.1ms\n","Speed: 9.4ms preprocess, 107.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 4 tvs, 12 laptops, 1 keyboard, 1 cell phone, 108.1ms\n","Speed: 4.2ms preprocess, 108.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 chair, 4 tvs, 12 laptops, 1 keyboard, 1 cell phone, 109.5ms\n","Speed: 3.7ms preprocess, 109.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 4 tvs, 14 laptops, 1 keyboard, 1 cell phone, 108.0ms\n","Speed: 3.8ms preprocess, 108.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 111.7ms\n","Speed: 3.5ms preprocess, 111.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 3 tvs, 14 laptops, 1 keyboard, 1 cell phone, 108.2ms\n","Speed: 5.0ms preprocess, 108.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 4 tvs, 14 laptops, 1 keyboard, 1 cell phone, 105.0ms\n","Speed: 4.1ms preprocess, 105.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 5 tvs, 14 laptops, 1 keyboard, 1 cell phone, 115.0ms\n","Speed: 4.8ms preprocess, 115.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 5 tvs, 14 laptops, 1 keyboard, 1 cell phone, 108.5ms\n","Speed: 3.0ms preprocess, 108.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 3 chairs, 3 tvs, 14 laptops, 1 keyboard, 1 cell phone, 111.7ms\n","Speed: 3.1ms preprocess, 111.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 3 chairs, 4 tvs, 15 laptops, 1 keyboard, 1 cell phone, 116.2ms\n","Speed: 4.4ms preprocess, 116.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 4 tvs, 15 laptops, 1 keyboard, 1 cell phone, 102.4ms\n","Speed: 6.0ms preprocess, 102.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 5 tvs, 14 laptops, 1 keyboard, 1 cell phone, 97.2ms\n","Speed: 3.0ms preprocess, 97.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 5 tvs, 14 laptops, 1 keyboard, 1 cell phone, 104.6ms\n","Speed: 4.0ms preprocess, 104.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 5 tvs, 14 laptops, 1 keyboard, 1 cell phone, 107.4ms\n","Speed: 5.2ms preprocess, 107.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 5 tvs, 14 laptops, 1 keyboard, 1 cell phone, 127.5ms\n","Speed: 4.8ms preprocess, 127.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 3 chairs, 5 tvs, 13 laptops, 1 keyboard, 113.0ms\n","Speed: 4.4ms preprocess, 113.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 5 tvs, 13 laptops, 1 keyboard, 113.0ms\n","Speed: 3.8ms preprocess, 113.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 4 tvs, 12 laptops, 1 keyboard, 126.3ms\n","Speed: 4.1ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 3 chairs, 4 tvs, 13 laptops, 1 keyboard, 122.0ms\n","Speed: 5.0ms preprocess, 122.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 4 tvs, 12 laptops, 1 keyboard, 132.4ms\n","Speed: 3.8ms preprocess, 132.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 5 tvs, 14 laptops, 1 keyboard, 117.8ms\n","Speed: 5.8ms preprocess, 117.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 4 tvs, 12 laptops, 1 keyboard, 120.1ms\n","Speed: 5.7ms preprocess, 120.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 3 tvs, 11 laptops, 1 keyboard, 119.0ms\n","Speed: 4.9ms preprocess, 119.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 4 chairs, 5 tvs, 11 laptops, 1 keyboard, 117.4ms\n","Speed: 5.5ms preprocess, 117.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 4 chairs, 4 tvs, 12 laptops, 1 keyboard, 117.9ms\n","Speed: 5.1ms preprocess, 117.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 1 cup, 4 chairs, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 138.6ms\n","Speed: 3.9ms preprocess, 138.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 4 chairs, 6 tvs, 11 laptops, 1 keyboard, 1 cell phone, 115.3ms\n","Speed: 5.7ms preprocess, 115.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 4 chairs, 6 tvs, 11 laptops, 1 keyboard, 130.1ms\n","Speed: 4.3ms preprocess, 130.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 4 chairs, 6 tvs, 12 laptops, 1 keyboard, 1 cell phone, 139.8ms\n","Speed: 4.4ms preprocess, 139.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 4 chairs, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 150.8ms\n","Speed: 4.2ms preprocess, 150.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 4 chairs, 4 tvs, 12 laptops, 1 keyboard, 1 cell phone, 131.2ms\n","Speed: 8.4ms preprocess, 131.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 158.0ms\n","Speed: 2.9ms preprocess, 158.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 148.3ms\n","Speed: 7.4ms preprocess, 148.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 4 chairs, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 142.4ms\n","Speed: 5.5ms preprocess, 142.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 4 chairs, 5 tvs, 12 laptops, 1 keyboard, 1 cell phone, 143.6ms\n","Speed: 4.4ms preprocess, 143.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 4 chairs, 4 tvs, 12 laptops, 1 keyboard, 1 cell phone, 155.1ms\n","Speed: 4.8ms preprocess, 155.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 4 chairs, 4 tvs, 11 laptops, 1 keyboard, 1 cell phone, 130.2ms\n","Speed: 5.6ms preprocess, 130.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 4 chairs, 4 tvs, 11 laptops, 1 keyboard, 1 cell phone, 102.5ms\n","Speed: 3.4ms preprocess, 102.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 3 chairs, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 105.2ms\n","Speed: 4.5ms preprocess, 105.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 6 tvs, 11 laptops, 1 keyboard, 1 cell phone, 114.8ms\n","Speed: 3.8ms preprocess, 114.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 6 tvs, 11 laptops, 1 keyboard, 1 cell phone, 94.4ms\n","Speed: 4.0ms preprocess, 94.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 5 tvs, 11 laptops, 1 keyboard, 1 cell phone, 102.8ms\n","Speed: 3.7ms preprocess, 102.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 3 tvs, 11 laptops, 1 keyboard, 1 cell phone, 100.7ms\n","Speed: 4.0ms preprocess, 100.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 4 tvs, 11 laptops, 1 keyboard, 1 cell phone, 110.5ms\n","Speed: 3.6ms preprocess, 110.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 3 tvs, 11 laptops, 1 keyboard, 1 cell phone, 101.7ms\n","Speed: 3.0ms preprocess, 101.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 3 chairs, 5 tvs, 11 laptops, 1 keyboard, 111.9ms\n","Speed: 4.6ms preprocess, 111.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 1 cup, 1 chair, 6 tvs, 11 laptops, 1 keyboard, 105.0ms\n","Speed: 4.0ms preprocess, 105.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 5 tvs, 11 laptops, 1 keyboard, 119.9ms\n","Speed: 3.1ms preprocess, 119.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 107.2ms\n","Speed: 4.4ms preprocess, 107.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 115.0ms\n","Speed: 4.6ms preprocess, 115.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 5 tvs, 13 laptops, 1 keyboard, 111.4ms\n","Speed: 4.7ms preprocess, 111.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 5 tvs, 11 laptops, 1 keyboard, 128.3ms\n","Speed: 3.6ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 1 chair, 6 tvs, 11 laptops, 1 keyboard, 111.1ms\n","Speed: 5.8ms preprocess, 111.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 5 tvs, 12 laptops, 1 keyboard, 116.3ms\n","Speed: 4.6ms preprocess, 116.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 1 chair, 5 tvs, 11 laptops, 1 keyboard, 121.8ms\n","Speed: 4.8ms preprocess, 121.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 1 chair, 5 tvs, 12 laptops, 1 keyboard, 112.8ms\n","Speed: 4.3ms preprocess, 112.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 1 chair, 5 tvs, 12 laptops, 1 keyboard, 116.5ms\n","Speed: 5.2ms preprocess, 116.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 1 chair, 7 tvs, 13 laptops, 1 keyboard, 108.6ms\n","Speed: 6.8ms preprocess, 108.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 1 chair, 8 tvs, 11 laptops, 1 keyboard, 105.9ms\n","Speed: 5.0ms preprocess, 105.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 8 tvs, 9 laptops, 1 keyboard, 1 cell phone, 110.4ms\n","Speed: 4.2ms preprocess, 110.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 8 tvs, 8 laptops, 1 keyboard, 1 cell phone, 110.6ms\n","Speed: 4.0ms preprocess, 110.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 8 tvs, 9 laptops, 1 keyboard, 1 cell phone, 112.0ms\n","Speed: 4.3ms preprocess, 112.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 7 tvs, 7 laptops, 1 keyboard, 1 cell phone, 111.8ms\n","Speed: 5.0ms preprocess, 111.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 8 laptops, 1 keyboard, 1 cell phone, 117.0ms\n","Speed: 3.4ms preprocess, 117.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 7 tvs, 9 laptops, 1 keyboard, 1 cell phone, 104.8ms\n","Speed: 4.9ms preprocess, 104.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 6 tvs, 8 laptops, 1 keyboard, 1 cell phone, 108.0ms\n","Speed: 3.3ms preprocess, 108.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 chair, 7 tvs, 9 laptops, 1 keyboard, 1 cell phone, 111.6ms\n","Speed: 4.5ms preprocess, 111.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 5 tvs, 8 laptops, 1 keyboard, 1 cell phone, 138.5ms\n","Speed: 4.0ms preprocess, 138.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 6 tvs, 11 laptops, 1 keyboard, 1 cell phone, 112.7ms\n","Speed: 5.8ms preprocess, 112.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 8 laptops, 1 keyboard, 1 cell phone, 110.1ms\n","Speed: 4.9ms preprocess, 110.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 8 tvs, 9 laptops, 1 keyboard, 1 cell phone, 126.6ms\n","Speed: 4.3ms preprocess, 126.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 7 tvs, 8 laptops, 1 keyboard, 1 cell phone, 107.6ms\n","Speed: 3.5ms preprocess, 107.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 7 tvs, 9 laptops, 1 keyboard, 1 cell phone, 108.2ms\n","Speed: 4.8ms preprocess, 108.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 8 tvs, 9 laptops, 1 keyboard, 112.5ms\n","Speed: 5.0ms preprocess, 112.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 6 tvs, 8 laptops, 1 keyboard, 104.6ms\n","Speed: 5.7ms preprocess, 104.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 6 tvs, 6 laptops, 1 keyboard, 115.4ms\n","Speed: 4.6ms preprocess, 115.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 6 tvs, 7 laptops, 1 keyboard, 106.9ms\n","Speed: 3.9ms preprocess, 106.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 5 tvs, 6 laptops, 1 keyboard, 118.7ms\n","Speed: 3.7ms preprocess, 118.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 5 tvs, 6 laptops, 1 keyboard, 107.7ms\n","Speed: 4.6ms preprocess, 107.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 4 tvs, 8 laptops, 1 keyboard, 112.4ms\n","Speed: 3.2ms preprocess, 112.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 4 tvs, 8 laptops, 1 keyboard, 135.4ms\n","Speed: 4.6ms preprocess, 135.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 7 tvs, 7 laptops, 1 keyboard, 115.2ms\n","Speed: 5.0ms preprocess, 115.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 7 tvs, 7 laptops, 1 keyboard, 153.1ms\n","Speed: 5.3ms preprocess, 153.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 7 tvs, 7 laptops, 1 keyboard, 120.7ms\n","Speed: 5.3ms preprocess, 120.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 7 tvs, 6 laptops, 1 keyboard, 122.0ms\n","Speed: 5.1ms preprocess, 122.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 7 tvs, 8 laptops, 1 keyboard, 121.0ms\n","Speed: 4.0ms preprocess, 121.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 7 tvs, 9 laptops, 1 keyboard, 113.8ms\n","Speed: 5.1ms preprocess, 113.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 6 tvs, 10 laptops, 1 keyboard, 121.2ms\n","Speed: 3.7ms preprocess, 121.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 7 tvs, 9 laptops, 1 keyboard, 103.2ms\n","Speed: 4.1ms preprocess, 103.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 6 tvs, 10 laptops, 1 keyboard, 106.6ms\n","Speed: 3.1ms preprocess, 106.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 7 tvs, 8 laptops, 1 keyboard, 1 cell phone, 119.0ms\n","Speed: 4.3ms preprocess, 119.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 7 tvs, 8 laptops, 1 keyboard, 1 cell phone, 101.0ms\n","Speed: 3.7ms preprocess, 101.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 7 tvs, 8 laptops, 1 keyboard, 1 cell phone, 121.0ms\n","Speed: 5.2ms preprocess, 121.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 7 tvs, 8 laptops, 1 keyboard, 1 cell phone, 104.7ms\n","Speed: 4.8ms preprocess, 104.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 7 tvs, 8 laptops, 1 keyboard, 1 cell phone, 107.9ms\n","Speed: 4.2ms preprocess, 107.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 7 tvs, 8 laptops, 1 keyboard, 1 cell phone, 110.3ms\n","Speed: 4.9ms preprocess, 110.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 1 chair, 7 tvs, 7 laptops, 1 keyboard, 1 cell phone, 124.0ms\n","Speed: 7.3ms preprocess, 124.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 1 chair, 7 tvs, 7 laptops, 1 keyboard, 1 cell phone, 117.5ms\n","Speed: 5.3ms preprocess, 117.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 1 chair, 7 tvs, 7 laptops, 1 keyboard, 1 cell phone, 121.5ms\n","Speed: 5.0ms preprocess, 121.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 7 tvs, 8 laptops, 1 keyboard, 1 cell phone, 134.2ms\n","Speed: 3.9ms preprocess, 134.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 chair, 7 tvs, 7 laptops, 1 keyboard, 1 cell phone, 110.4ms\n","Speed: 6.3ms preprocess, 110.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 chair, 7 tvs, 9 laptops, 1 keyboard, 1 cell phone, 114.8ms\n","Speed: 5.1ms preprocess, 114.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 1 chair, 7 tvs, 8 laptops, 1 keyboard, 1 cell phone, 111.3ms\n","Speed: 5.2ms preprocess, 111.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 7 tvs, 9 laptops, 1 keyboard, 1 cell phone, 114.9ms\n","Speed: 5.3ms preprocess, 114.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 6 tvs, 9 laptops, 1 keyboard, 1 cell phone, 106.0ms\n","Speed: 5.3ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 2 chairs, 7 tvs, 9 laptops, 1 keyboard, 112.9ms\n","Speed: 3.0ms preprocess, 112.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 7 tvs, 9 laptops, 1 keyboard, 1 cell phone, 111.8ms\n","Speed: 4.4ms preprocess, 111.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 6 tvs, 7 laptops, 1 keyboard, 1 cell phone, 111.6ms\n","Speed: 3.1ms preprocess, 111.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 6 tvs, 8 laptops, 1 keyboard, 107.5ms\n","Speed: 4.1ms preprocess, 107.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 8 laptops, 1 keyboard, 110.5ms\n","Speed: 4.0ms preprocess, 110.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 6 tvs, 9 laptops, 1 keyboard, 100.6ms\n","Speed: 4.3ms preprocess, 100.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 6 tvs, 8 laptops, 1 keyboard, 105.8ms\n","Speed: 4.3ms preprocess, 105.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 5 tvs, 9 laptops, 1 keyboard, 108.7ms\n","Speed: 4.6ms preprocess, 108.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 6 tvs, 9 laptops, 1 keyboard, 1 cell phone, 137.1ms\n","Speed: 6.6ms preprocess, 137.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 6 tvs, 8 laptops, 1 keyboard, 175.9ms\n","Speed: 9.2ms preprocess, 175.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 5 tvs, 9 laptops, 1 keyboard, 169.2ms\n","Speed: 3.0ms preprocess, 169.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 6 tvs, 10 laptops, 1 keyboard, 127.0ms\n","Speed: 4.0ms preprocess, 127.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 10 laptops, 1 keyboard, 130.4ms\n","Speed: 4.8ms preprocess, 130.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 6 tvs, 9 laptops, 1 keyboard, 153.7ms\n","Speed: 4.8ms preprocess, 153.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 10 laptops, 1 keyboard, 173.7ms\n","Speed: 8.8ms preprocess, 173.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 12 laptops, 1 keyboard, 198.9ms\n","Speed: 9.5ms preprocess, 198.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 10 laptops, 1 keyboard, 171.6ms\n","Speed: 4.2ms preprocess, 171.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 11 laptops, 1 keyboard, 122.9ms\n","Speed: 5.3ms preprocess, 122.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 122.3ms\n","Speed: 5.2ms preprocess, 122.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 4 tvs, 11 laptops, 1 keyboard, 120.5ms\n","Speed: 5.4ms preprocess, 120.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 5 tvs, 13 laptops, 1 keyboard, 132.2ms\n","Speed: 4.2ms preprocess, 132.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 chairs, 7 tvs, 10 laptops, 1 keyboard, 129.7ms\n","Speed: 5.0ms preprocess, 129.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 7 tvs, 12 laptops, 1 keyboard, 134.6ms\n","Speed: 4.6ms preprocess, 134.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 7 tvs, 12 laptops, 1 keyboard, 117.9ms\n","Speed: 5.7ms preprocess, 117.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 7 tvs, 13 laptops, 1 keyboard, 123.6ms\n","Speed: 4.1ms preprocess, 123.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 chairs, 5 tvs, 13 laptops, 1 keyboard, 121.4ms\n","Speed: 5.3ms preprocess, 121.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 6 tvs, 12 laptops, 1 keyboard, 119.3ms\n","Speed: 3.9ms preprocess, 119.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 5 tvs, 13 laptops, 1 keyboard, 107.4ms\n","Speed: 4.5ms preprocess, 107.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 5 tvs, 13 laptops, 1 keyboard, 109.2ms\n","Speed: 4.5ms preprocess, 109.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 13 laptops, 1 keyboard, 123.3ms\n","Speed: 5.4ms preprocess, 123.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 2 chairs, 6 tvs, 10 laptops, 1 keyboard, 110.1ms\n","Speed: 3.7ms preprocess, 110.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 chairs, 6 tvs, 10 laptops, 1 keyboard, 104.8ms\n","Speed: 4.5ms preprocess, 104.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 2 chairs, 7 tvs, 10 laptops, 1 keyboard, 104.0ms\n","Speed: 4.5ms preprocess, 104.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 6 tvs, 12 laptops, 1 keyboard, 105.9ms\n","Speed: 4.0ms preprocess, 105.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 chairs, 6 tvs, 11 laptops, 1 keyboard, 110.0ms\n","Speed: 4.2ms preprocess, 110.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 12 laptops, 1 keyboard, 104.8ms\n","Speed: 4.1ms preprocess, 104.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 2 chairs, 6 tvs, 12 laptops, 1 keyboard, 117.4ms\n","Speed: 3.4ms preprocess, 117.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 13 laptops, 1 keyboard, 112.0ms\n","Speed: 13.5ms preprocess, 112.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 6 tvs, 13 laptops, 1 keyboard, 114.2ms\n","Speed: 3.3ms preprocess, 114.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 14 laptops, 1 keyboard, 113.1ms\n","Speed: 4.5ms preprocess, 113.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 14 laptops, 1 keyboard, 105.1ms\n","Speed: 6.5ms preprocess, 105.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 6 tvs, 14 laptops, 1 keyboard, 106.0ms\n","Speed: 5.5ms preprocess, 106.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 6 tvs, 10 laptops, 1 keyboard, 108.9ms\n","Speed: 3.5ms preprocess, 108.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 2 chairs, 5 tvs, 9 laptops, 1 keyboard, 101.4ms\n","Speed: 4.2ms preprocess, 101.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 5 tvs, 9 laptops, 1 keyboard, 107.6ms\n","Speed: 4.4ms preprocess, 107.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 2 chairs, 6 tvs, 7 laptops, 1 keyboard, 112.6ms\n","Speed: 5.4ms preprocess, 112.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 6 tvs, 10 laptops, 1 keyboard, 118.1ms\n","Speed: 3.4ms preprocess, 118.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 103.0ms\n","Speed: 5.4ms preprocess, 103.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 107.0ms\n","Speed: 7.3ms preprocess, 107.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 4 tvs, 10 laptops, 1 keyboard, 101.2ms\n","Speed: 4.3ms preprocess, 101.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 5 tvs, 10 laptops, 1 keyboard, 130.4ms\n","Speed: 3.1ms preprocess, 130.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 5 tvs, 12 laptops, 1 keyboard, 104.2ms\n","Speed: 4.2ms preprocess, 104.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 chair, 4 tvs, 12 laptops, 1 keyboard, 102.0ms\n","Speed: 5.2ms preprocess, 102.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 chair, 4 tvs, 14 laptops, 1 keyboard, 113.1ms\n","Speed: 5.5ms preprocess, 113.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 chair, 5 tvs, 12 laptops, 1 keyboard, 116.7ms\n","Speed: 4.2ms preprocess, 116.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 1 chair, 5 tvs, 12 laptops, 1 keyboard, 106.8ms\n","Speed: 4.6ms preprocess, 106.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 105.7ms\n","Speed: 5.5ms preprocess, 105.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 106.3ms\n","Speed: 4.4ms preprocess, 106.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 105.4ms\n","Speed: 3.8ms preprocess, 105.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 105.5ms\n","Speed: 4.9ms preprocess, 105.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 120.6ms\n","Speed: 3.1ms preprocess, 120.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 103.2ms\n","Speed: 4.8ms preprocess, 103.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 3 chairs, 5 tvs, 12 laptops, 1 keyboard, 113.1ms\n","Speed: 3.9ms preprocess, 113.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 100.6ms\n","Speed: 5.2ms preprocess, 100.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 107.4ms\n","Speed: 5.3ms preprocess, 107.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 2 chairs, 5 tvs, 10 laptops, 1 keyboard, 104.9ms\n","Speed: 4.3ms preprocess, 104.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 3 chairs, 5 tvs, 10 laptops, 1 keyboard, 108.2ms\n","Speed: 2.9ms preprocess, 108.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 5 tvs, 13 laptops, 1 keyboard, 97.7ms\n","Speed: 5.0ms preprocess, 97.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 6 tvs, 13 laptops, 1 keyboard, 113.5ms\n","Speed: 2.9ms preprocess, 113.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 3 chairs, 6 tvs, 12 laptops, 1 keyboard, 103.4ms\n","Speed: 4.3ms preprocess, 103.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 3 chairs, 6 tvs, 12 laptops, 1 keyboard, 122.3ms\n","Speed: 4.7ms preprocess, 122.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 6 tvs, 12 laptops, 1 keyboard, 97.9ms\n","Speed: 5.4ms preprocess, 97.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 5 tvs, 11 laptops, 1 keyboard, 111.0ms\n","Speed: 3.8ms preprocess, 111.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 5 tvs, 11 laptops, 1 keyboard, 97.1ms\n","Speed: 4.0ms preprocess, 97.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 cups, 3 chairs, 5 tvs, 11 laptops, 1 keyboard, 136.9ms\n","Speed: 2.9ms preprocess, 136.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 cups, 3 chairs, 5 tvs, 11 laptops, 1 keyboard, 101.8ms\n","Speed: 4.8ms preprocess, 101.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 cups, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 105.4ms\n","Speed: 4.0ms preprocess, 105.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 1 chair, 5 tvs, 12 laptops, 1 keyboard, 115.2ms\n","Speed: 4.2ms preprocess, 115.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 cups, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 117.3ms\n","Speed: 3.0ms preprocess, 117.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 5 tvs, 13 laptops, 1 keyboard, 107.5ms\n","Speed: 4.3ms preprocess, 107.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 6 tvs, 13 laptops, 1 keyboard, 105.9ms\n","Speed: 7.5ms preprocess, 105.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 2 chairs, 5 tvs, 14 laptops, 1 keyboard, 106.1ms\n","Speed: 3.3ms preprocess, 106.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 2 chairs, 6 tvs, 14 laptops, 1 keyboard, 102.2ms\n","Speed: 4.3ms preprocess, 102.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 3 chairs, 6 tvs, 14 laptops, 1 keyboard, 121.9ms\n","Speed: 5.4ms preprocess, 121.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 6 tvs, 14 laptops, 1 keyboard, 136.0ms\n","Speed: 4.2ms preprocess, 136.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 6 tvs, 13 laptops, 1 keyboard, 125.0ms\n","Speed: 5.1ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 cups, 3 chairs, 6 tvs, 12 laptops, 1 keyboard, 125.1ms\n","Speed: 4.2ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 2 cups, 2 chairs, 6 tvs, 13 laptops, 1 keyboard, 117.2ms\n","Speed: 5.0ms preprocess, 117.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 6 tvs, 13 laptops, 1 keyboard, 111.9ms\n","Speed: 4.0ms preprocess, 111.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 6 tvs, 13 laptops, 1 keyboard, 126.4ms\n","Speed: 4.6ms preprocess, 126.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 6 tvs, 13 laptops, 1 keyboard, 116.5ms\n","Speed: 4.0ms preprocess, 116.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 6 tvs, 12 laptops, 1 keyboard, 121.0ms\n","Speed: 3.7ms preprocess, 121.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 6 tvs, 12 laptops, 1 keyboard, 109.9ms\n","Speed: 3.1ms preprocess, 109.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 7 tvs, 12 laptops, 1 keyboard, 117.6ms\n","Speed: 3.2ms preprocess, 117.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 7 tvs, 12 laptops, 1 keyboard, 115.4ms\n","Speed: 7.1ms preprocess, 115.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 7 tvs, 13 laptops, 1 keyboard, 164.0ms\n","Speed: 3.3ms preprocess, 164.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 6 tvs, 12 laptops, 1 keyboard, 148.9ms\n","Speed: 3.1ms preprocess, 148.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 6 tvs, 11 laptops, 1 keyboard, 167.0ms\n","Speed: 3.3ms preprocess, 167.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 7 tvs, 11 laptops, 1 keyboard, 172.1ms\n","Speed: 3.5ms preprocess, 172.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 7 tvs, 11 laptops, 1 keyboard, 171.1ms\n","Speed: 6.2ms preprocess, 171.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 7 tvs, 9 laptops, 1 keyboard, 172.7ms\n","Speed: 4.9ms preprocess, 172.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 7 tvs, 10 laptops, 1 keyboard, 158.5ms\n","Speed: 4.4ms preprocess, 158.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 7 tvs, 10 laptops, 1 keyboard, 171.9ms\n","Speed: 3.7ms preprocess, 171.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 7 tvs, 11 laptops, 1 keyboard, 140.9ms\n","Speed: 3.5ms preprocess, 140.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 3 chairs, 7 tvs, 12 laptops, 1 keyboard, 106.6ms\n","Speed: 2.9ms preprocess, 106.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 7 tvs, 12 laptops, 1 keyboard, 105.1ms\n","Speed: 3.3ms preprocess, 105.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 7 tvs, 13 laptops, 1 keyboard, 105.3ms\n","Speed: 3.7ms preprocess, 105.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 7 tvs, 13 laptops, 1 keyboard, 114.7ms\n","Speed: 3.4ms preprocess, 114.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 7 tvs, 13 laptops, 1 keyboard, 102.1ms\n","Speed: 3.1ms preprocess, 102.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 7 tvs, 13 laptops, 1 keyboard, 108.7ms\n","Speed: 3.1ms preprocess, 108.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 7 tvs, 13 laptops, 1 keyboard, 105.7ms\n","Speed: 3.4ms preprocess, 105.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 7 tvs, 13 laptops, 1 keyboard, 114.7ms\n","Speed: 3.0ms preprocess, 114.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 8 tvs, 13 laptops, 1 keyboard, 104.4ms\n","Speed: 3.4ms preprocess, 104.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 8 tvs, 13 laptops, 1 keyboard, 115.0ms\n","Speed: 3.0ms preprocess, 115.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 8 tvs, 12 laptops, 1 keyboard, 105.3ms\n","Speed: 3.1ms preprocess, 105.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 9 tvs, 14 laptops, 1 keyboard, 126.8ms\n","Speed: 5.0ms preprocess, 126.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 8 tvs, 14 laptops, 1 keyboard, 118.3ms\n","Speed: 3.6ms preprocess, 118.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 6 tvs, 14 laptops, 1 keyboard, 131.5ms\n","Speed: 3.2ms preprocess, 131.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 7 tvs, 13 laptops, 1 keyboard, 111.4ms\n","Speed: 3.1ms preprocess, 111.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 7 tvs, 14 laptops, 1 keyboard, 128.0ms\n","Speed: 4.9ms preprocess, 128.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 3 chairs, 8 tvs, 13 laptops, 1 keyboard, 122.3ms\n","Speed: 6.3ms preprocess, 122.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 8 tvs, 14 laptops, 1 keyboard, 125.8ms\n","Speed: 5.6ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 7 tvs, 14 laptops, 1 keyboard, 119.4ms\n","Speed: 3.6ms preprocess, 119.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 3 chairs, 7 tvs, 12 laptops, 1 keyboard, 121.5ms\n","Speed: 3.8ms preprocess, 121.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 3 chairs, 7 tvs, 12 laptops, 1 keyboard, 121.7ms\n","Speed: 4.1ms preprocess, 121.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 3 chairs, 6 tvs, 9 laptops, 1 keyboard, 112.9ms\n","Speed: 4.9ms preprocess, 112.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 persons, 1 cup, 2 chairs, 7 tvs, 10 laptops, 1 keyboard, 110.7ms\n","Speed: 5.3ms preprocess, 110.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 1 cup, 2 chairs, 6 tvs, 10 laptops, 1 keyboard, 113.9ms\n","Speed: 4.2ms preprocess, 113.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 7 tvs, 9 laptops, 1 keyboard, 117.5ms\n","Speed: 2.9ms preprocess, 117.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 7 tvs, 11 laptops, 1 keyboard, 107.6ms\n","Speed: 3.6ms preprocess, 107.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 1 cup, 2 chairs, 7 tvs, 12 laptops, 1 keyboard, 107.2ms\n","Speed: 3.4ms preprocess, 107.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 persons, 1 cup, 2 chairs, 7 tvs, 12 laptops, 1 keyboard, 118.4ms\n","Speed: 3.6ms preprocess, 118.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 persons, 1 cup, 2 chairs, 6 tvs, 11 laptops, 1 keyboard, 108.5ms\n","Speed: 4.7ms preprocess, 108.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 110.2ms\n","Speed: 3.3ms preprocess, 110.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 persons, 1 cup, 2 chairs, 5 tvs, 12 laptops, 1 keyboard, 111.6ms\n","Speed: 3.4ms preprocess, 111.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","Finished object detection on video frames.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6248c71a","executionInfo":{"status":"ok","timestamp":1751652296090,"user_tz":-360,"elapsed":70,"user":{"displayName":"sadat rahman","userId":"00315844507455805433"}},"outputId":"5abc88a5-6a80-4ee9-bf24-efaff5ac0e30"},"source":["raised_hand_individuals = []\n","\n","# Define a threshold for considering a hand \"raised\" (e.g., hand bounding box center is above the person's chest level)\n","# This threshold might need adjustment based on the specific video and detection model\n","raised_threshold_ratio = 0.4 # Consider hand raised if its center is in the top 40% of the person's bounding box\n","\n","for frame_number, frame_results in enumerate(frame_detection_results):\n","    persons = [det for det in frame_results[0].boxes.data.tolist() if int(det[5]) == 0] # Assuming class 0 is 'person'\n","    hands = [det for det in frame_results[0].boxes.data.tolist() if int(det[5]) in [1, 2]] # Assuming classes 1 and 2 are potential hand classes (adjust as needed)\n","\n","    for person in persons:\n","        person_xmin, person_ymin, person_xmax, person_ymax, person_confidence, person_class = person\n","        person_height = person_ymax - person_ymin\n","        person_chest_level = person_ymin + person_height * (1 - raised_threshold_ratio) # Calculate the y-coordinate of the chest level\n","\n","        for hand in hands:\n","            hand_xmin, hand_ymin, hand_xmax, hand_ymax, hand_confidence, hand_class = hand\n","            hand_center_y = (hand_ymin + hand_ymax) / 2\n","\n","            # Check if the hand is within the horizontal range of the person and above the chest level\n","            if hand_xmin > person_xmin and hand_xmax < person_xmax and hand_center_y < person_chest_level:\n","                raised_hand_individuals.append((frame_number, person, hand))\n","\n","print(f\"Found {len(raised_hand_individuals)} instances of potentially raised hands.\")"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 0 instances of potentially raised hands.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1ed09ed","executionInfo":{"status":"ok","timestamp":1751652329094,"user_tz":-360,"elapsed":48,"user":{"displayName":"sadat rahman","userId":"00315844507455805433"}},"outputId":"d9ae3ea3-1403-40d7-f8c3-1d92bad7fe3f"},"source":["# Inspect frame_detection_results to find the correct class labels for 'hand'\n","# Assuming frame_detection_results is a list of Results objects\n","if frame_detection_results:\n","    # Take the first frame's results as an example\n","    example_results = frame_detection_results[0]\n","\n","    # Get the names of the detected classes\n","    detected_classes = example_results[0].names\n","\n","    print(\"Detected classes and their corresponding IDs:\")\n","    for class_id, class_name in detected_classes.items():\n","        print(f\"ID: {class_id}, Name: {class_name}\")\n","\n","else:\n","    print(\"No detection results available.\")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Detected classes and their corresponding IDs:\n","ID: 0, Name: person\n","ID: 1, Name: bicycle\n","ID: 2, Name: car\n","ID: 3, Name: motorcycle\n","ID: 4, Name: airplane\n","ID: 5, Name: bus\n","ID: 6, Name: train\n","ID: 7, Name: truck\n","ID: 8, Name: boat\n","ID: 9, Name: traffic light\n","ID: 10, Name: fire hydrant\n","ID: 11, Name: stop sign\n","ID: 12, Name: parking meter\n","ID: 13, Name: bench\n","ID: 14, Name: bird\n","ID: 15, Name: cat\n","ID: 16, Name: dog\n","ID: 17, Name: horse\n","ID: 18, Name: sheep\n","ID: 19, Name: cow\n","ID: 20, Name: elephant\n","ID: 21, Name: bear\n","ID: 22, Name: zebra\n","ID: 23, Name: giraffe\n","ID: 24, Name: backpack\n","ID: 25, Name: umbrella\n","ID: 26, Name: handbag\n","ID: 27, Name: tie\n","ID: 28, Name: suitcase\n","ID: 29, Name: frisbee\n","ID: 30, Name: skis\n","ID: 31, Name: snowboard\n","ID: 32, Name: sports ball\n","ID: 33, Name: kite\n","ID: 34, Name: baseball bat\n","ID: 35, Name: baseball glove\n","ID: 36, Name: skateboard\n","ID: 37, Name: surfboard\n","ID: 38, Name: tennis racket\n","ID: 39, Name: bottle\n","ID: 40, Name: wine glass\n","ID: 41, Name: cup\n","ID: 42, Name: fork\n","ID: 43, Name: knife\n","ID: 44, Name: spoon\n","ID: 45, Name: bowl\n","ID: 46, Name: banana\n","ID: 47, Name: apple\n","ID: 48, Name: sandwich\n","ID: 49, Name: orange\n","ID: 50, Name: broccoli\n","ID: 51, Name: carrot\n","ID: 52, Name: hot dog\n","ID: 53, Name: pizza\n","ID: 54, Name: donut\n","ID: 55, Name: cake\n","ID: 56, Name: chair\n","ID: 57, Name: couch\n","ID: 58, Name: potted plant\n","ID: 59, Name: bed\n","ID: 60, Name: dining table\n","ID: 61, Name: toilet\n","ID: 62, Name: tv\n","ID: 63, Name: laptop\n","ID: 64, Name: mouse\n","ID: 65, Name: remote\n","ID: 66, Name: keyboard\n","ID: 67, Name: cell phone\n","ID: 68, Name: microwave\n","ID: 69, Name: oven\n","ID: 70, Name: toaster\n","ID: 71, Name: sink\n","ID: 72, Name: refrigerator\n","ID: 73, Name: book\n","ID: 74, Name: clock\n","ID: 75, Name: vase\n","ID: 76, Name: scissors\n","ID: 77, Name: teddy bear\n","ID: 78, Name: hair drier\n","ID: 79, Name: toothbrush\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51727aed","executionInfo":{"status":"ok","timestamp":1751652351933,"user_tz":-360,"elapsed":29,"user":{"displayName":"sadat rahman","userId":"00315844507455805433"}},"outputId":"777bbec3-2cdf-401f-e831-3a86e084bfca"},"source":["# Review the detected_classes variable from the previous step\n","print(\"Detected classes and their corresponding IDs (from previous step):\")\n","for class_id, class_name in detected_classes.items():\n","    print(f\"ID: {class_id}, Name: {class_name}\")\n","\n","# Based on the list, identify potential proxy classes for hands.\n","# Since hands are not directly detected, we'll look for small objects that people might hold up.\n","# Examples from the detected list could include 'cell phone' (ID 67), 'book' (ID 84),\n","# or perhaps even smaller objects if the model is detailed enough.\n","# Let's select 'cell phone' (ID 67) and 'book' (ID 84) as potential proxies for this attempt.\n","# Note: This is an assumption and may not accurately represent raised hands.\n","potential_hand_proxies_ids = [67, 84] # IDs for 'cell phone' and 'book'\n","\n","print(f\"\\nSelected potential hand proxy class IDs: {potential_hand_proxies_ids}\")"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Detected classes and their corresponding IDs (from previous step):\n","ID: 0, Name: person\n","ID: 1, Name: bicycle\n","ID: 2, Name: car\n","ID: 3, Name: motorcycle\n","ID: 4, Name: airplane\n","ID: 5, Name: bus\n","ID: 6, Name: train\n","ID: 7, Name: truck\n","ID: 8, Name: boat\n","ID: 9, Name: traffic light\n","ID: 10, Name: fire hydrant\n","ID: 11, Name: stop sign\n","ID: 12, Name: parking meter\n","ID: 13, Name: bench\n","ID: 14, Name: bird\n","ID: 15, Name: cat\n","ID: 16, Name: dog\n","ID: 17, Name: horse\n","ID: 18, Name: sheep\n","ID: 19, Name: cow\n","ID: 20, Name: elephant\n","ID: 21, Name: bear\n","ID: 22, Name: zebra\n","ID: 23, Name: giraffe\n","ID: 24, Name: backpack\n","ID: 25, Name: umbrella\n","ID: 26, Name: handbag\n","ID: 27, Name: tie\n","ID: 28, Name: suitcase\n","ID: 29, Name: frisbee\n","ID: 30, Name: skis\n","ID: 31, Name: snowboard\n","ID: 32, Name: sports ball\n","ID: 33, Name: kite\n","ID: 34, Name: baseball bat\n","ID: 35, Name: baseball glove\n","ID: 36, Name: skateboard\n","ID: 37, Name: surfboard\n","ID: 38, Name: tennis racket\n","ID: 39, Name: bottle\n","ID: 40, Name: wine glass\n","ID: 41, Name: cup\n","ID: 42, Name: fork\n","ID: 43, Name: knife\n","ID: 44, Name: spoon\n","ID: 45, Name: bowl\n","ID: 46, Name: banana\n","ID: 47, Name: apple\n","ID: 48, Name: sandwich\n","ID: 49, Name: orange\n","ID: 50, Name: broccoli\n","ID: 51, Name: carrot\n","ID: 52, Name: hot dog\n","ID: 53, Name: pizza\n","ID: 54, Name: donut\n","ID: 55, Name: cake\n","ID: 56, Name: chair\n","ID: 57, Name: couch\n","ID: 58, Name: potted plant\n","ID: 59, Name: bed\n","ID: 60, Name: dining table\n","ID: 61, Name: toilet\n","ID: 62, Name: tv\n","ID: 63, Name: laptop\n","ID: 64, Name: mouse\n","ID: 65, Name: remote\n","ID: 66, Name: keyboard\n","ID: 67, Name: cell phone\n","ID: 68, Name: microwave\n","ID: 69, Name: oven\n","ID: 70, Name: toaster\n","ID: 71, Name: sink\n","ID: 72, Name: refrigerator\n","ID: 73, Name: book\n","ID: 74, Name: clock\n","ID: 75, Name: vase\n","ID: 76, Name: scissors\n","ID: 77, Name: teddy bear\n","ID: 78, Name: hair drier\n","ID: 79, Name: toothbrush\n","\n","Selected potential hand proxy class IDs: [67, 84]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"903ca69a","executionInfo":{"status":"ok","timestamp":1751652370647,"user_tz":-360,"elapsed":41,"user":{"displayName":"sadat rahman","userId":"00315844507455805433"}},"outputId":"89672ba4-c35a-49ef-fbe2-bb481694f01a"},"source":["raised_hand_individuals = []\n","\n","# Use the potential_hand_proxies_ids identified in the previous step\n","# potential_hand_proxies_ids = [67, 84] # IDs for 'cell phone' and 'book'\n","\n","# Refine the raised threshold logic. A hand/proxy is raised if it's significantly above\n","# the person's chest level and within the horizontal bounds of the person.\n","# We will use the raised_threshold_ratio defined previously (0.4).\n","# A hand/proxy is considered above chest level if its bottom y-coordinate is above the person's chest level.\n","# It is considered within horizontal bounds if its x-range overlaps with the person's x-range.\n","\n","for frame_number, frame_results in enumerate(frame_detection_results):\n","    # Ensure there are detection results for the current frame\n","    if not frame_results or not hasattr(frame_results[0], 'boxes'):\n","        continue\n","\n","    detections = frame_results[0].boxes.data.tolist()\n","\n","    persons = [det for det in detections if int(det[5]) == 0] # Assuming class 0 is 'person'\n","    potential_hands = [det for det in detections if int(det[5]) in potential_hand_proxies_ids]\n","\n","    for person in persons:\n","        person_xmin, person_ymin, person_xmax, person_ymax, person_confidence, person_class = person\n","        person_height = person_ymax - person_ymin\n","        # Calculate the y-coordinate of the chest level (e.g., 60% down from the top of the person's bounding box)\n","        person_chest_level = person_ymin + person_height * (1 - raised_threshold_ratio)\n","\n","        for potential_hand in potential_hands:\n","            hand_xmin, hand_ymin, hand_xmax, hand_ymax, hand_confidence, hand_class = potential_hand\n","\n","            # Check for horizontal overlap: the right edge of the hand must be to the right of the person's left edge,\n","            # AND the left edge of the hand must be to the left of the person's right edge.\n","            horizontal_overlap = (hand_xmax > person_xmin) and (hand_xmin < person_xmax)\n","\n","            # Check if the bottom of the hand bounding box is above the person's chest level\n","            above_chest_level = hand_ymax < person_chest_level\n","\n","            # Consider the potential hand raised if it has horizontal overlap and is above the chest level\n","            if horizontal_overlap and above_chest_level:\n","                raised_hand_individuals.append((frame_number, person, potential_hand))\n","\n","print(f\"Found {len(raised_hand_individuals)} instances of potentially raised hands based on proxy classes.\")\n","print(\"Note: These detections are based on proxy classes ('cell phone', 'book') and may not be actual raised hands.\")"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 0 instances of potentially raised hands based on proxy classes.\n","Note: These detections are based on proxy classes ('cell phone', 'book') and may not be actual raised hands.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d92cf501","executionInfo":{"status":"ok","timestamp":1751652391600,"user_tz":-360,"elapsed":76,"user":{"displayName":"sadat rahman","userId":"00315844507455805433"}},"outputId":"5b864ada-a42f-4a80-e931-8c4ec898490e"},"source":["print(\"Analysis of 'desk_video.mp4' for Raised Hands:\")\n","print(\"-\" * 40)\n","print(\"Based on the object detection analysis performed, no instances of raised hands were identified in the video.\")\n","print(\"\\nLikely Reasons for No Detection:\")\n","print(\"1. The object detection model used (YOLOv8n) does not have a dedicated 'hand' class.\")\n","print(\"2. The attempt to use proxy classes ('cell phone', 'book') as indicators for hands did not yield any positive results based on the defined spatial criteria.\")\n","print(\"\\nLimitations of the Current Approach:\")\n","print(\"Identifying raised hands accurately requires a model specifically trained to detect hands or a more sophisticated pose estimation approach that can analyze limb positions.\")\n","print(\"The current method, relying on a generic object detection model and simple spatial relationships of proxy objects, is insufficient for this task.\")\n","print(\"\\nSummary of Process Undertaken:\")\n","print(\"- Loaded the video file 'desk_video.mp4'.\")\n","print(\"- Iterated through each frame of the video.\")\n","print(\"- Performed object detection using a pre-trained YOLOv8n model to identify persons and other objects.\")\n","print(\"- Attempted to identify potential 'raised hands' by looking for proxy objects ('cell phone', 'book') above the estimated chest level of detected persons.\")\n","print(\"- Analyzed the spatial relationship between detected persons and potential hand proxy objects.\")\n","\n","print(\"\\nConclusion:\")\n","print(\"Due to the limitations of the object detection model and the lack of positive results from the proxy class analysis, no instances of raised hands were found in 'desk_video.mp4' based on this analysis.\")"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Analysis of 'desk_video.mp4' for Raised Hands:\n","----------------------------------------\n","Based on the object detection analysis performed, no instances of raised hands were identified in the video.\n","\n","Likely Reasons for No Detection:\n","1. The object detection model used (YOLOv8n) does not have a dedicated 'hand' class.\n","2. The attempt to use proxy classes ('cell phone', 'book') as indicators for hands did not yield any positive results based on the defined spatial criteria.\n","\n","Limitations of the Current Approach:\n","Identifying raised hands accurately requires a model specifically trained to detect hands or a more sophisticated pose estimation approach that can analyze limb positions.\n","The current method, relying on a generic object detection model and simple spatial relationships of proxy objects, is insufficient for this task.\n","\n","Summary of Process Undertaken:\n","- Loaded the video file 'desk_video.mp4'.\n","- Iterated through each frame of the video.\n","- Performed object detection using a pre-trained YOLOv8n model to identify persons and other objects.\n","- Attempted to identify potential 'raised hands' by looking for proxy objects ('cell phone', 'book') above the estimated chest level of detected persons.\n","- Analyzed the spatial relationship between detected persons and potential hand proxy objects.\n","\n","Conclusion:\n","Due to the limitations of the object detection model and the lack of positive results from the proxy class analysis, no instances of raised hands were found in 'desk_video.mp4' based on this analysis.\n"]}]}]}